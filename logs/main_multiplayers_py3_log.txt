Loaded experiments configuration from 'configuration.py' :
configuration = {'players': [<PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f3c462a80f0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f3c224cae10>], 'repetitions': 20, 'horizon': 10000, 'collisionModel': <function onlyUniqUserGetsReward at 0x7f3c224b52f0>, 'n_jobs': -1, 'finalRanksOnAverage': True, 'averageOn': 0.001, 'environment': [{'params': [0.1, 0.5, 0.9], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}], 'verbosity': 6}
plots is already a directory here...
Number of players in the multi-players game: 2
Time horizon: 10000
Number of repetitions: 20
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.1, 0.5, 0.9], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.1, 0.5, 0.9]
 - with 'arms' = [B(0.1), B(0.5), B(0.9)]
 - with 'nbArms' = 3
 - with 'maxArm' = 0.9
Number of environments to try: 1

Evaluating environment: <MAB{'maxArm': 0.9, 'nbArms': 3, 'arms': [B(0.1), B(0.5), B(0.9)]}>
- Adding player #1 = #1<MEGA(c: 0.1, d: 0.01, p0: 0.6, alpha: 0.5, beta: 0.8)> ...
  Using this already created player 'player' = #1<MEGA(c: 0.1, d: 0.01, p0: 0.6, alpha: 0.5, beta: 0.8)> ...
- Adding player #2 = #2<MEGA(c: 0.1, d: 0.01, p0: 0.6, alpha: 0.5, beta: 0.8)> ...
  Using this already created player 'player' = #2<MEGA(c: 0.1, d: 0.01, p0: 0.6, alpha: 0.5, beta: 0.8)> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #1, '#1<MEGA(c: 0.1, d: 0.01, p0: 0.6, alpha: 0.5, beta: 0.8)>'	was ranked	1 / 2 for this simulation (last rewards = 4594.4).
- Player #2, '#2<MEGA(c: 0.1, d: 0.01, p0: 0.6, alpha: 0.5, beta: 0.8)>'	was ranked	2 / 2 for this simulation (last rewards = 4010.95).
plots/MP__M2_T10000_N20__2_algos is already a directory here...
- Plotting the decentralized rewards, and saving the plot to plots/MP__M2_T10000_N20__2_algos/main____env1-1_8108031878684817670.png ...
Saving to plots/MP__M2_T10000_N20__2_algos/main____env1-1_8108031878684817670.png ...
- Plotting the centralized  rewards, and saving the plot to plots/MP__M2_T10000_N20__2_algos/main_RewardsCentralized____env1-1_8108031878684817670.png ...
Saving to plots/MP__M2_T10000_N20__2_algos/main_RewardsCentralized____env1-1_8108031878684817670.png ...
 - Plotting the total nb of collision as a function of time, and saving the plot to plots/MP__M2_T10000_N20__2_algos/main_NbCollisions_RewardsCentralized____env1-1_8108031878684817670.png ...
 - Plotting the cumulated total nb of collision as a function of time, and saving the plot to plots/MP__M2_T10000_N20__2_algos/main_NbCollisionsCum_NbCollisions_RewardsCentralized____env1-1_8108031878684817670.png ...
 - Plotting the frequency of collision in each arm, and saving the plot to plots/MP__M2_T10000_N20__2_algos/main_FrequencyCollisions_NbCollisionsCum_NbCollisions_RewardsCentralized____env1-1_8108031878684817670.png ...
  - For #$0$: $B(0.1)$,	frequency of collisions is 2.5e-05  ...
  - For #$1$: $B(0.5)$,	frequency of collisions is 3.5e-05  ...
  - For #$2$: $B(0.9)$,	frequency of collisions is 1.5e-05  ...
