Loaded experiments configuration from 'configuration.py' :
configuration = {'verbosity': 6, 'environment': [{'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}], 'collisionModel': <function onlyUniqUserGetsReward at 0x7fc9c9844268>, 'n_jobs': -1, 'averageOn': 0.001, 'horizon': 10000, 'finalRanksOnAverage': True, 'players': [<PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c97786a0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9778ac8>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9778ef0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c977a358>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c977a780>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c977aba8>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c977afd0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9772438>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9772860>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9772c88>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c97670f0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9767518>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9767940>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9767d68>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c97631d0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c97635f8>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fc9c9763a20>], 'repetitions': 20}
plots is already a directory here...
Number of players in the multi-players game: 17
Time horizon: 10000
Number of repetitions: 20
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
Number of environments to try: 1

Evaluating environment: <MAB{'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'nbArms': 17, 'maxArm': 0.85}>
- Adding player #1 = #1<Thompson> ...
  Using this already created player 'player' = #1<Thompson> ...
- Adding player #2 = #2<Thompson> ...
  Using this already created player 'player' = #2<Thompson> ...
- Adding player #3 = #3<Thompson> ...
  Using this already created player 'player' = #3<Thompson> ...
- Adding player #4 = #4<Thompson> ...
  Using this already created player 'player' = #4<Thompson> ...
- Adding player #5 = #5<Thompson> ...
  Using this already created player 'player' = #5<Thompson> ...
- Adding player #6 = #6<Thompson> ...
  Using this already created player 'player' = #6<Thompson> ...
- Adding player #7 = #7<Thompson> ...
  Using this already created player 'player' = #7<Thompson> ...
- Adding player #8 = #8<Thompson> ...
  Using this already created player 'player' = #8<Thompson> ...
- Adding player #9 = #9<Thompson> ...
  Using this already created player 'player' = #9<Thompson> ...
- Adding player #10 = #10<Thompson> ...
  Using this already created player 'player' = #10<Thompson> ...
- Adding player #11 = #11<Thompson> ...
  Using this already created player 'player' = #11<Thompson> ...
- Adding player #12 = #12<Thompson> ...
  Using this already created player 'player' = #12<Thompson> ...
- Adding player #13 = #13<Thompson> ...
  Using this already created player 'player' = #13<Thompson> ...
- Adding player #14 = #14<Thompson> ...
  Using this already created player 'player' = #14<Thompson> ...
- Adding player #15 = #15<Thompson> ...
  Using this already created player 'player' = #15<Thompson> ...
- Adding player #16 = #16<Thompson> ...
  Using this already created player 'player' = #16<Thompson> ...
- Adding player #17 = #17<Thompson> ...
  Using this already created player 'player' = #17<Thompson> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #12, '#12<Thompson>'	was ranked	1 / 17 for this simulation (last regret = 4162.450).
- Player #3, '#3<Thompson>'	was ranked	2 / 17 for this simulation (last regret = 4437.250).
- Player #4, '#4<Thompson>'	was ranked	3 / 17 for this simulation (last regret = 4564.200).
- Player #13, '#13<Thompson>'	was ranked	4 / 17 for this simulation (last regret = 4728.100).
- Player #14, '#14<Thompson>'	was ranked	5 / 17 for this simulation (last regret = 4791.650).
- Player #7, '#7<Thompson>'	was ranked	6 / 17 for this simulation (last regret = 4906.500).
- Player #11, '#11<Thompson>'	was ranked	7 / 17 for this simulation (last regret = 4936.700).
- Player #10, '#10<Thompson>'	was ranked	8 / 17 for this simulation (last regret = 5064.500).
- Player #9, '#9<Thompson>'	was ranked	9 / 17 for this simulation (last regret = 5285.000).
- Player #17, '#17<Thompson>'	was ranked	10 / 17 for this simulation (last regret = 5366.750).
- Player #16, '#16<Thompson>'	was ranked	11 / 17 for this simulation (last regret = 5383.850).
- Player #8, '#8<Thompson>'	was ranked	12 / 17 for this simulation (last regret = 5432.700).
- Player #5, '#5<Thompson>'	was ranked	13 / 17 for this simulation (last regret = 5552.050).
- Player #1, '#1<Thompson>'	was ranked	14 / 17 for this simulation (last regret = 5669.950).
- Player #6, '#6<Thompson>'	was ranked	15 / 17 for this simulation (last regret = 5766.500).
- Player #2, '#2<Thompson>'	was ranked	16 / 17 for this simulation (last regret = 6074.800).
- Player #15, '#15<Thompson>'	was ranked	17 / 17 for this simulation (last regret = 6351.250).
plots/MP__M17_T10000_N20__17_algos is already a directory here...
- Plotting the decentralized rewards, and saving the plot to plots/MP__M17_T10000_N20__17_algos/main____env1-1_4478917326988773544.png ...
Saving to plots/MP__M17_T10000_N20__17_algos/main____env1-1_4478917326988773544.png ...
- Plotting the centralized  rewards, and saving the plot to plots/MP__M17_T10000_N20__17_algos/main_RewardsCentralized____env1-1_4478917326988773544.png ...
Saving to plots/MP__M17_T10000_N20__17_algos/main_RewardsCentralized____env1-1_4478917326988773544.png ...
 - Plotting the frequency of collision in each arm, and saving the plot to plots/MP__M17_T10000_N20__17_algos/main_FrequencyCollisions_RewardsCentralized____env1-1_4478917326988773544.png ...
  - For #$0$: B(0.005),	frequency of collisions is 0.001  ...
  - For #$1$: B(0.01),	frequency of collisions is 0.001  ...
  - For #$2$: B(0.015),	frequency of collisions is 0.001  ...
  - For #$3$: B(0.02),	frequency of collisions is 0.001  ...
  - For #$4$: B(0.3),	frequency of collisions is 0.039  ...
  - For #$5$: B(0.35),	frequency of collisions is 0.043  ...
  - For #$6$: B(0.4),	frequency of collisions is 0.040  ...
  - For #$7$: B(0.45),	frequency of collisions is 0.036  ...
  - For #$8$: B(0.5),	frequency of collisions is 0.038  ...
  - For #$9$: B(0.55),	frequency of collisions is 0.031  ...
  - For #$10$: B(0.6),	frequency of collisions is 0.036  ...
  - For #$11$: B(0.78),	frequency of collisions is 0.034  ...
  - For #$12$: B(0.8),	frequency of collisions is 0.035  ...
  - For #$13$: B(0.82),	frequency of collisions is 0.032  ...
  - For #$14$: B(0.83),	frequency of collisions is 0.031  ...
  - For #$15$: B(0.84),	frequency of collisions is 0.033  ...
  - For #$16$: B(0.85),	frequency of collisions is 0.033  ...
Saving to plots/MP__M17_T10000_N20__17_algos/main_FrequencyCollisions_RewardsCentralized____env1-1_4478917326988773544.png ...
ons is 0.022  ...
  - For #$12$: B(0.8),	frequency of collisions is 0.023  ...
  - For #$13$: B(0.82),	frequency of collisions is 0.022  ...
  - For #$14$: B(0.83),	frequency of collisions is 0.022  ...
  - For #$15$: B(0.84),	frequency of collisions is 0.023  ...
  - For #$16$: B(0.85),	frequency of collisions is 0.023  ...
Saving to plots/MP__M17_T10000_N20__17_algos/main_FrequencyCollisions_RewardsCentralized____env1-1_589159748092214358.png ...
