Loaded experiments configuration from 'configuration.py' :
configuration = {'finalRanksOnAverage': True, 'averageOn': 0.001, 'horizon': 20000, 'verbosity': 6, 'n_jobs': -1, 'repetitions': 20, 'players': [CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus, CentralizedMultiplePlay: klUCBPlus], 'environment': [{'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}], 'collisionModel': <function onlyUniqUserGetsReward at 0x7fc435cc9d08>}
plots/ is already a directory here...
Number of players in the multi-players game: 12
Time horizon: 20000
Number of repetitions: 20
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
Number of environments to try: 1

Evaluating environment: <MAB{'maxArm': 0.84999999999999998, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'nbArms': 17}>
- Adding player #1 = #1<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #1<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #2 = #2<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #2<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #3 = #3<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #3<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #4 = #4<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #4<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #5 = #5<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #5<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #6 = #6<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #6<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #7 = #7<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #7<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #8 = #8<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #8<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #9 = #9<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #9<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #10 = #10<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #10<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #11 = #11<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #11<CentralizedMultiplePlay: klUCBPlus> ...
- Adding player #12 = #12<CentralizedMultiplePlay: klUCBPlus> ...
  Using this already created player 'player' = #12<CentralizedMultiplePlay: klUCBPlus> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #4, '#4<CentralizedMultiplePlay: klUCBPlus>'	was ranked	1 / 12 for this simulation (last rewards = 12955).
- Player #9, '#9<CentralizedMultiplePlay: klUCBPlus>'	was ranked	2 / 12 for this simulation (last rewards = 12938.9).
- Player #1, '#1<CentralizedMultiplePlay: klUCBPlus>'	was ranked	3 / 12 for this simulation (last rewards = 12938.4).
- Player #6, '#6<CentralizedMultiplePlay: klUCBPlus>'	was ranked	4 / 12 for this simulation (last rewards = 12937.1).
- Player #2, '#2<CentralizedMultiplePlay: klUCBPlus>'	was ranked	5 / 12 for this simulation (last rewards = 12936.8).
- Player #7, '#7<CentralizedMultiplePlay: klUCBPlus>'	was ranked	6 / 12 for this simulation (last rewards = 12936.5).
- Player #5, '#5<CentralizedMultiplePlay: klUCBPlus>'	was ranked	7 / 12 for this simulation (last rewards = 12935.4).
- Player #10, '#10<CentralizedMultiplePlay: klUCBPlus>'	was ranked	8 / 12 for this simulation (last rewards = 12929).
- Player #3, '#3<CentralizedMultiplePlay: klUCBPlus>'	was ranked	9 / 12 for this simulation (last rewards = 12924).
- Player #8, '#8<CentralizedMultiplePlay: klUCBPlus>'	was ranked	10 / 12 for this simulation (last rewards = 12916).
- Player #12, '#12<CentralizedMultiplePlay: klUCBPlus>'	was ranked	11 / 12 for this simulation (last rewards = 12916).
- Player #11, '#11<CentralizedMultiplePlay: klUCBPlus>'	was ranked	12 / 12 for this simulation (last rewards = 12909.2).


- Plotting the decentralized rewards, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main____env1-1_3824424860991444814.png ...


- Plotting the centralized regret, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_RegretCentralized____env1-1_3824424860991444814.png ...
  - For 12 player, our lower bound gave = 150.1359450266453 ...
  - For 12 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 33.73452466467231 ...
 - Our lowerbound = 150.1359450266453,
 - anandkumar_lowerbound = 33.73452466467231


- Plotting the centralized regret, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_RegretCentralized____env1-1_3824424860991444814.png ...
  - For 12 player, our lower bound gave = 150.1359450266453 ...
  - For 12 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 33.73452466467231 ...
 - Our lowerbound = 150.1359450266453,
 - anandkumar_lowerbound = 33.73452466467231


- Plotting the normalized centralized rewards, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_NormalizedRewardsCentralized____env1-1_3824424860991444814.png ...
  - For 12 player, our lower bound gave = 150.1359450266453 ...
  - For 12 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 33.73452466467231 ...
 - Our lowerbound = 150.1359450266453,
 - anandkumar_lowerbound = 33.73452466467231


- Plotting the cumulative number of switches, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_CumNbSwitchs____env1-1_3824424860991444814.png ...
 - Plotting the probability of picking the best arm, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_BestArmPulls____env1-1_3824424860991444814.png ...
 - Plotting the cumulative number of pulls of all arms, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_NormalizedAllPulls____env1-1_3824424860991444814.png ...
 - Plotting the total nb of collision as a function of time, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_NbCollisions____env1-1_3824424860991444814.png ...
 - Plotting the cumulated total nb of collision as a function of time, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_CumNbCollisions____env1-1_3824424860991444814.png ...
 - Plotting the frequency of collision in each arm, and saving the plot to plots/MP__M12_T20000_N20__12_algos/main_FrequencyCollisions____env1-1_3824424860991444814.png ...
  - For #$0$: $B(0.005)$,	frequency of collisions is 0  ...
  - For #$1$: $B(0.01)$,	frequency of collisions is 0  ...
  - For #$2$: $B(0.015)$,	frequency of collisions is 0  ...
  - For #$3$: $B(0.02)$,	frequency of collisions is 0  ...
  - For #$4$: $B(0.3)$,	frequency of collisions is 0  ...
  - For #$5$: $B(0.35)$,	frequency of collisions is 0  ...
  - For #$6$: $B(0.4)$,	frequency of collisions is 0  ...
  - For #$7$: $B(0.45)$,	frequency of collisions is 0  ...
  - For #$8$: $B(0.5)$,	frequency of collisions is 0  ...
  - For #$9$: $B(0.55)$,	frequency of collisions is 0  ...
  - For #$10$: $B(0.6)$,	frequency of collisions is 0  ...
  - For #$11$: $B(0.78)$,	frequency of collisions is 0  ...
  - For #$12$: $B(0.8)$,	frequency of collisions is 0  ...
  - For #$13$: $B(0.82)$,	frequency of collisions is 0  ...
  - For #$14$: $B(0.83)$,	frequency of collisions is 0  ...
  - For #$15$: $B(0.84)$,	frequency of collisions is 0  ...
  - For #$16$: $B(0.85)$,	frequency of collisions is 0  ...
==> No collisions to plot ... Stopping now  ...
