Loaded experiments configuration from 'configuration.py' :
configuration = {'horizon': 10000, 'averageOn': 0.001, 'finalRanksOnAverage': True, 'collisionModel': <function closerOneGetsReward at 0x7f9615dc4048>, 'players': [<PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f9602f120f0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f9602f12518>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f9602f12940>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f9602f12d68>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f9602f171d0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7f9602f175f8>], 'verbosity': 6, 'repetitions': 20, 'environment': [{'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]}], 'n_jobs': -1}
plots is already a directory here...
Number of players in the multi-players game: 6
Time horizon: 10000
Number of repetitions: 20
Using collision model: closerOneGetsReward
  Detail: None
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
Number of environments to try: 1

Evaluating environment: <MAB{'maxArm': 0.85, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'nbArms': 17}>
- Adding player #1 = #1<Thompson> ...
  Using this already created player 'player' = #1<Thompson> ...
- Adding player #2 = #2<Thompson> ...
  Using this already created player 'player' = #2<Thompson> ...
- Adding player #3 = #3<Thompson> ...
  Using this already created player 'player' = #3<Thompson> ...
- Adding player #4 = #4<Thompson> ...
  Using this already created player 'player' = #4<Thompson> ...
- Adding player #5 = #5<Thompson> ...
  Using this already created player 'player' = #5<Thompson> ...
- Adding player #6 = #6<Thompson> ...
  Using this already created player 'player' = #6<Thompson> ...
I just generated a new distances vector, for 6 players : distances = [ 0.53299189  0.16101148  0.70570336  0.70154064  0.32502854  0.37109425] ...
I just generated a new distances vector, for 6 players : distances = [ 0.53299189  0.16101148  0.70570336  0.70154064  0.32502854  0.37109425] ...
I just generated a new distances vector, for 6 players : distances = [ 0.53299189  0.16101148  0.70570336  0.70154064  0.32502854  0.37109425] ...
I just generated a new distances vector, for 6 players : distances = [ 0.53299189  0.16101148  0.70570336  0.70154064  0.32502854  0.37109425] ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #2, '#2<Thompson>'	was ranked	1 / 6 for this simulation (last rewards = 8.33e+03).
- Player #5, '#5<Thompson>'	was ranked	2 / 6 for this simulation (last rewards = 7.89e+03).
- Player #6, '#6<Thompson>'	was ranked	3 / 6 for this simulation (last rewards = 7.37e+03).
- Player #1, '#1<Thompson>'	was ranked	4 / 6 for this simulation (last rewards = 6.88e+03).
- Player #4, '#4<Thompson>'	was ranked	5 / 6 for this simulation (last rewards = 6.1e+03).
- Player #3, '#3<Thompson>'	was ranked	6 / 6 for this simulation (last rewards = 5.47e+03).
plots/MP__M6_T10000_N20__6_algos is already a directory here...
- Plotting the decentralized rewards, and saving the plot to plots/MP__M6_T10000_N20__6_algos/main____env1-1_4633681464925132157.png ...
Saving to plots/MP__M6_T10000_N20__6_algos/main____env1-1_4633681464925132157.png ...
- Plotting the centralized  rewards, and saving the plot to plots/MP__M6_T10000_N20__6_algos/main_RewardsCentralized____env1-1_4633681464925132157.png ...
Saving to plots/MP__M6_T10000_N20__6_algos/main_RewardsCentralized____env1-1_4633681464925132157.png ...
 - Plotting the frequency of collision in each arm, and saving the plot to plots/MP__M6_T10000_N20__6_algos/main_FrequencyCollisions_RewardsCentralized____env1-1_4633681464925132157.png ...
[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m/home/lilian/ownCloud/cloud.openmailbox.org/Th√®se_2016-17/src/AlgoBandits.git/main_multiplayers.py[0m in [0;36m<module>[0;34m()[0m
[1;32m     93[0m         [0mprint[0m[0;34m([0m[0;34m" - Plotting the frequency of collision in each arm, and saving the plot to {} ..."[0m[0;34m.[0m[0mformat[0m[0;34m([0m[0msavefig[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0m
[1;32m     94[0m         [0;31m# evaluation.plotFrequencyCollisions(envId, savefig=savefig, piechart=piechart)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 95[0;31m         [0mevaluation[0m[0;34m.[0m[0mplotFrequencyCollisions[0m[0;34m([0m[0menvId[0m[0;34m,[0m [0mpiechart[0m[0;34m=[0m[0mpiechart[0m[0;34m)[0m[0;34m[0m[0m
[0m[1;32m     96[0m [0;34m[0m[0m
[1;32m     97[0m         [0;32mif[0m [0minteractive[0m[0;34m:[0m[0;34m[0m[0m

[0;32m/home/lilian/ownCloud/cloud.openmailbox.org/Th√®se_2016-17/src/AlgoBandits.git/Environment/EvaluatorMultiPlayers.py[0m in [0;36mplotFrequencyCollisions[0;34m(self, environmentId, savefig, piechart)[0m
[1;32m    249[0m         [0;32massert[0m [0;36m0[0m [0;34m<=[0m [0mnp[0m[0;34m.[0m[0msum[0m[0;34m([0m[0mY[0m[0;34m)[0m [0;34m<=[0m [0;36m1[0m[0;34m,[0m [0;34m"Error: the sum of collisions = {}, averaged by horizon and nbPlayers, cannot be outside of [0, 1] ..."[0m[0;34m.[0m[0mformat[0m[0;34m([0m[0mnp[0m[0;34m.[0m[0msum[0m[0;34m([0m[0mY[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0m
[1;32m    250[0m         [0;32mfor[0m [0marmId[0m[0;34m,[0m [0marm[0m [0;32min[0m [0menumerate[0m[0;34m([0m[0mself[0m[0;34m.[0m[0menvs[0m[0;34m[[0m[0menvironmentId[0m[0;34m][0m[0;34m.[0m[0marms[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0m
[0;32m--> 251[0;31m             [0mprint[0m[0;34m([0m[0;34m"  - For {},\tfrequency of collisions is {:.gf}  ..."[0m[0;34m.[0m[0mformat[0m[0;34m([0m[0mlabels[0m[0;34m[[0m[0marmId[0m[0;34m][0m[0;34m,[0m [0mY[0m[0;34m[[0m[0marmId[0m[0;34m][0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0m
[0m[1;32m    252[0m             [0;32mif[0m [0mY[0m[0;34m[[0m[0marmId[0m[0;34m][0m [0;34m<[0m [0;36m1e-3[0m[0;34m:[0m  [0;31m# Do not display small slices[0m[0;34m[0m[0m
[1;32m    253[0m                 [0mlabels[0m[0;34m[[0m[0marmId[0m[0;34m][0m [0;34m=[0m [0;34m''[0m[0;34m[0m[0m

[0;31mValueError[0m: Format specifier missing precision
