 - Setting dpi of all figures to 110 ...
 - Setting 'figsize' of all figures to (19.8, 10.8) ...
 - One new child, of index 0, and class #1<CentralizedMultiplePlay: UCB($\alpha=1$)> ...
 - One new child, of index 1, and class #2<CentralizedMultiplePlay: UCB($\alpha=1$)> ...
 - One new child, of index 2, and class #3<CentralizedMultiplePlay: UCB($\alpha=1$)> ...
 - One new child, of index 3, and class #4<CentralizedMultiplePlay: UCB($\alpha=1$)> ...
 - One new child, of index 4, and class #5<CentralizedMultiplePlay: UCB($\alpha=1$)> ...
 - One new child, of index 5, and class #6<CentralizedMultiplePlay: UCB($\alpha=1$)> ...
Loaded experiments configuration from 'configuration.py' :
configuration = {'averageOn': 0.001, 'environment': [{'params': [0.10000000000000001, 0.20000000000000001, 0.30000000000000004, 0.40000000000000002, 0.5, 0.59999999999999998, 0.70000000000000007, 0.80000000000000004, 0.90000000000000002], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}], 'verbosity': 6, 'finalRanksOnAverage': True, 'successive_players': [[CentralizedMultiplePlay: UCB($\alpha=1$), CentralizedMultiplePlay: UCB($\alpha=1$), CentralizedMultiplePlay: UCB($\alpha=1$), CentralizedMultiplePlay: UCB($\alpha=1$), CentralizedMultiplePlay: UCB($\alpha=1$), CentralizedMultiplePlay: UCB($\alpha=1$)], [MusicalChair($T_0=2000$), MusicalChair($T_0=2000$), MusicalChair($T_0=2000$), MusicalChair($T_0=2000$), MusicalChair($T_0=2000$), MusicalChair($T_0=2000$)], [MusicalChair($T_0=1000$), MusicalChair($T_0=1000$), MusicalChair($T_0=1000$), MusicalChair($T_0=1000$), MusicalChair($T_0=1000$), MusicalChair($T_0=1000$)], [MusicalChair($T_0=100$), MusicalChair($T_0=100$), MusicalChair($T_0=100$), MusicalChair($T_0=100$), MusicalChair($T_0=100$), MusicalChair($T_0=100$)], [UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$)], [UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$), UCB($\alpha=1$)], [KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern)], [KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern), KL-UCB+(Bern)], [Thompson, Thompson, Thompson, Thompson, Thompson, Thompson], [BayesUCB, BayesUCB, BayesUCB, BayesUCB, BayesUCB, BayesUCB], [BayesUCB, BayesUCB, BayesUCB, BayesUCB, BayesUCB, BayesUCB]], 'players': [Thompson, Thompson, Thompson, Thompson, Thompson, Thompson], 'n_jobs': -1, 'delta_t_save': 1, 'collisionModel': <function onlyUniqUserGetsReward at 0x7f485982d2f0>, 'repetitions': 4, 'horizon': 20000}
plots/ is already a directory here...
Number of players in the multi-players game: 6
Time horizon: 20000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.10000000000000001, 0.20000000000000001, 0.30000000000000004, 0.40000000000000002, 0.5, 0.59999999999999998, 0.70000000000000007, 0.80000000000000004, 0.90000000000000002], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.10000000000000001, 0.20000000000000001, 0.30000000000000004, 0.40000000000000002, 0.5, 0.59999999999999998, 0.70000000000000007, 0.80000000000000004, 0.90000000000000002]
 - with 'arms' = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]
 - with 'nbArms' = 9
 - with 'maxArm' = 0.9
 - with 'minArm' = 0.1
Number of environments to try: 1

Evaluating environment: <MAB{'maxArm': 0.90000000000000002, 'nbArms': 9, 'minArm': 0.10000000000000001, 'arms': [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]}>
- Adding player #1 = #1<Thompson> ...
  Using this already created player 'player' = #1<Thompson> ...
- Adding player #2 = #2<Thompson> ...
  Using this already created player 'player' = #2<Thompson> ...
- Adding player #3 = #3<Thompson> ...
  Using this already created player 'player' = #3<Thompson> ...
- Adding player #4 = #4<Thompson> ...
  Using this already created player 'player' = #4<Thompson> ...
- Adding player #5 = #5<Thompson> ...
  Using this already created player 'player' = #5<Thompson> ...
- Adding player #6 = #6<Thompson> ...
  Using this already created player 'player' = #6<Thompson> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #5, '#5<Thompson>'	was ranked	1 / 6 for this simulation (last rewards = 14837.8).
- Player #3, '#3<Thompson>'	was ranked	2 / 6 for this simulation (last rewards = 14327).
- Player #4, '#4<Thompson>'	was ranked	3 / 6 for this simulation (last rewards = 12858.2).
- Player #1, '#1<Thompson>'	was ranked	4 / 6 for this simulation (last rewards = 12314).
- Player #2, '#2<Thompson>'	was ranked	5 / 6 for this simulation (last rewards = 12312.2).
- Player #6, '#6<Thompson>'	was ranked	6 / 6 for this simulation (last rewards = 10450.2).


- Plotting the decentralized rewards
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main____env1-1_4551926786850491852.png ...
Saving to plots/MP__M6_T20000_N4__6_algos/main____env1-1_4551926786850491852.png ...


- Plotting the centralized fairness
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_FairnessStd____env1-1_4551926786850491852.png ...
Saving to plots/MP__M6_T20000_N4__6_algos/main_FairnessStd____env1-1_4551926786850491852.png ...


- Plotting the centralized regret
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_RegretCentralized____env1-1_4551926786850491852.png ...
  - For 6 player, our lower bound gave = 48.843533096611566 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 15.030372473468088 ...
 - Our lowerbound = 48.8,
 - anandkumar_lowerbound = 15
Saving to plots/MP__M6_T20000_N4__6_algos/main_RegretCentralized____env1-1_4551926786850491852.png ...


- Plotting the centralized regret
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_RegretCentralized_semilogx____env1-1_4551926786850491852.png ...
  - For 6 player, our lower bound gave = 48.843533096611566 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 15.030372473468088 ...
 - Our lowerbound = 48.8,
 - anandkumar_lowerbound = 15
Saving to plots/MP__M6_T20000_N4__6_algos/main_RegretCentralized_semilogx____env1-1_4551926786850491852.png ...


- Plotting the centralized regret
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_RegretCentralized_FirstTerm____env1-1_4551926786850491852.png ...
  - For 6 player, our lower bound gave = 48.843533096611566 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 15.030372473468088 ...
 - Our lowerbound = 48.8,
 - anandkumar_lowerbound = 15
Saving to plots/MP__M6_T20000_N4__6_algos/main_RegretCentralized_FirstTerm____env1-1_4551926786850491852.png ...


- Plotting the number of switches
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_NbSwitchs____env1-1_4551926786850491852.png ...
Saving to plots/MP__M6_T20000_N4__6_algos/main_NbSwitchs____env1-1_4551926786850491852.png ...


- Plotting the cumulative number of switches
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_CumNbSwitchs____env1-1_4551926786850491852.png ...
Saving to plots/MP__M6_T20000_N4__6_algos/main_CumNbSwitchs____env1-1_4551926786850491852.png ...
 - Plotting the probability of picking the best arm
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_BestArmPulls____env1-1_4551926786850491852.png ...
Saving to plots/MP__M6_T20000_N4__6_algos/main_BestArmPulls____env1-1_4551926786850491852.png ...
 - Plotting the total nb of collision as a function of time
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_NbCollisions____env1-1_4551926786850491852.png ...
Saving to plots/MP__M6_T20000_N4__6_algos/main_NbCollisions____env1-1_4551926786850491852.png ...
 - Plotting the cumulated total nb of collision as a function of time
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_CumNbCollisions____env1-1_4551926786850491852.png ...
Saving to plots/MP__M6_T20000_N4__6_algos/main_CumNbCollisions____env1-1_4551926786850491852.png ...
 - Plotting the frequency of collision in each arm
  and saving the plot to plots/MP__M6_T20000_N4__6_algos/main_FrequencyCollisions____env1-1_4551926786850491852.png ...
  - For #$0$: $B(0.1)$ ($0.0%$$\%$),	frequency of collisions is 0.000108333  ...
  - For #$1$: $B(0.2)$ ($0.0%$$\%$),	frequency of collisions is 0.0001625  ...
  - For #$2$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.000385417  ...
  - For #$3$: $B(0.4)$ ($0.1%$$\%$),	frequency of collisions is 0.000702083  ...
  - For #$4$: $B(0.5)$ ($0.1%$$\%$),	frequency of collisions is 0.00113333  ...
  - For #$5$: $B(0.6)$ ($0.2%$$\%$),	frequency of collisions is 0.00164792  ...
  - For #$6$: $B(0.7)$ ($0.2%$$\%$),	frequency of collisions is 0.00178542  ...
  - For #$7$: $B(0.8)$ ($0.2%$$\%$),	frequency of collisions is 0.00190625  ...
  - For #$8$: $B(0.9)$ ($0.2%$$\%$),	frequency of collisions is 0.00177917  ...
Saving to plots/MP__M6_T20000_N4__6_algos/main_FrequencyCollisions____env1-1_4551926786850491852.png ...
Done for simulations main_multiplayers.py ...
