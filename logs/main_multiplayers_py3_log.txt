Loaded experiments configuration from 'configuration.py' :
configuration = {'verbosity': 8, 'players': [{'archtype': <class 'Policies.Uniform.Uniform'>, 'params': {}}, {'archtype': <class 'Policies.TakeFixedArm.TakeFixedArm'>, 'params': {'armIndex': 16}}, {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [13, 14, 15, 16]}}, {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [6, 7, 8, 9]}}, {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 15, 16]}}, {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 2, 3]}}, {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {}}, {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {}}, {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {}}], 'environment': [{'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]}], 'averageOn': 0.001, 'n_jobs': -1, 'finalRanksOnAverage': True, 'collisionModel': <function onlyUniqUserGetsReward at 0x7fcb82d5da60>, 'repetitions': 20, 'horizon': 10000}
plots is already a directory here...
Number of players in the multi-players game: 9
Time horizon: 10000
Number of repetitions: 20
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Number of environments to try: 1

Evaluating environment: <MAB{'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.85, 'nbArms': 17}>
- Adding player #1 = {'archtype': <class 'Policies.Uniform.Uniform'>, 'params': {}} ...
- Adding player #2 = {'archtype': <class 'Policies.TakeFixedArm.TakeFixedArm'>, 'params': {'armIndex': 16}} ...
- Adding player #3 = {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [13, 14, 15, 16]}} ...
- Adding player #4 = {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [6, 7, 8, 9]}} ...
- Adding player #5 = {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 15, 16]}} ...
- Adding player #6 = {'archtype': <class 'Policies.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 2, 3]}} ...
- Adding player #7 = {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {}} ...
- Adding player #8 = {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {}} ...
- Adding player #9 = {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {}} ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player 'BayesUCB'	was ranked	1 / 9 for this simulation (last regret = 1278.850).
- Player 'Thompson'	was ranked	2 / 9 for this simulation (last regret = 1673.100).
- Player 'klUCB'	was ranked	3 / 9 for this simulation (last regret = 2288.100).
- Player 'TakeFixedArm(16)'	was ranked	4 / 9 for this simulation (last regret = 3998.650).
- Player 'UniformOnSome([6, 7, 8, 9])'	was ranked	5 / 9 for this simulation (last regret = 4080.900).
- Player 'UniformOnSome([13, 14, 15, 16])'	was ranked	6 / 9 for this simulation (last regret = 4756.400).
- Player 'Uniform'	was ranked	7 / 9 for this simulation (last regret = 6238.150).
- Player 'UniformOnSome([0, 1, 15, 16])'	was ranked	8 / 9 for this simulation (last regret = 7002.650).
- Player 'UniformOnSome([0, 1, 2, 3])'	was ranked	9 / 9 for this simulation (last regret = 8380.850).
- Plotting the decentralized rewards, and saving the plot to plots/MP__M9_T10000_N20__9_algos/main____env1-1_2945113159512188178.png ...
Saving to plots/MP__M9_T10000_N20__9_algos/main____env1-1_2945113159512188178.png ...
 - Plotting the probability of picking the best arm, and saving the plot to plots/MP__M9_T10000_N20__9_algos/main_BestArmPulls____env1-1_2945113159512188178.png ...
Saving to plots/MP__M9_T10000_N20__9_algos/main_BestArmPulls____env1-1_2945113159512188178.png ...
 - Plotting the probability of transmission on a free channel, and saving the plot to plots/MP__M9_T10000_N20__9_algos/main_FreeTransmissions_BestArmPulls____env1-1_2945113159512188178.png ...
Saving to plots/MP__M9_T10000_N20__9_algos/main_FreeTransmissions_BestArmPulls____env1-1_2945113159512188178.png ...
 - Plotting the frequency of collision in each arm, and saving the plot to plots/MP__M9_T10000_N20__9_algos/main_FrequencyCollisions_FreeTransmissions_BestArmPulls____env1-1_2945113159512188178.png ...
  - For #$1$: B(0.005), frequency of collisions is 0.0  ...
  - For #$2$: B(0.01), frequency of collisions is 0.0  ...
  - For #$3$: B(0.015), frequency of collisions is 0.0  ...
  - For #$4$: B(0.02), frequency of collisions is 0.0  ...
  - For #$5$: B(0.3), frequency of collisions is 0.0  ...
  - For #$6$: B(0.35), frequency of collisions is 0.0  ...
  - For #$7$: B(0.4), frequency of collisions is 0.0  ...
  - For #$8$: B(0.45), frequency of collisions is 0.0  ...
  - For #$9$: B(0.5), frequency of collisions is 0.0  ...
  - For #$10$: B(0.55), frequency of collisions is 0.0  ...
  - For #$11$: B(0.6), frequency of collisions is 0.0  ...
  - For #$12$: B(0.78), frequency of collisions is 0.0  ...
  - For #$13$: B(0.8), frequency of collisions is 0.0  ...
  - For #$14$: B(0.82), frequency of collisions is 0.0  ...
  - For #$15$: B(0.83), frequency of collisions is 0.0002  ...
  - For #$16$: B(0.84), frequency of collisions is 0.0  ...
  - For #$17$: B(0.85), frequency of collisions is 0.5858  ...
Saving to plots/MP__M9_T10000_N20__9_algos/main_FrequencyCollisions_FreeTransmissions_BestArmPulls____env1-1_2945113159512188178.png ...
