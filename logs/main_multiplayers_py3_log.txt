Loaded experiments configuration from 'configuration.py' :
configuration = {'repetitions': 20, 'finalRanksOnAverage': True, 'n_jobs': -1, 'averageOn': 0.005, 'environment': [{'params': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}], 'collisionModel': <function onlyUniqUserGetsReward at 0x7f72e6eed7b8>, 'players': [{'archtype': <class 'PoliciesMultiPlayers.TakeFixedArm.TakeFixedArm'>, 'params': {'armIndex': 8}}, {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 8]}}, {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [5, 6, 7, 8]}}, {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [2, 3, 4, 5]}}, {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 6, 8]}}, {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 2]}}], 'horizon': 100, 'verbosity': 5}
plots is already a directory here...
Number of players in the multi-players game: 6
Time horizon: 100
Number of repetitions: 20
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one an arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    
Number of environments to try: 1

Evaluating environment: <MAB{'maxArm': 0.9, 'nbArms': 9, 'arms': [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]}>
- Adding player #1 = {'archtype': <class 'PoliciesMultiPlayers.TakeFixedArm.TakeFixedArm'>, 'params': {'armIndex': 8}} ...
- Adding player #2 = {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 8]}} ...
- Adding player #3 = {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [5, 6, 7, 8]}} ...
- Adding player #4 = {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [2, 3, 4, 5]}} ...
- Adding player #5 = {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 6, 8]}} ...
- Adding player #6 = {'archtype': <class 'PoliciesMultiPlayers.UniformOnSome.UniformOnSome'>, 'params': {'armIndexes': [0, 1, 2]}} ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player 'UniformOnSome([2, 3, 4, 5])'	was ranked	1 / 6 for this simulation (last regret = -0.500).
- Player 'UniformOnSome([5, 6, 7, 8])'	was ranked	2 / 6 for this simulation (last regret = -0.400).
- Player 'TakeFixedArm(8)'	was ranked	3 / 6 for this simulation (last regret = -0.250).
- Player 'UniformOnSome([0, 1, 2])'	was ranked	4 / 6 for this simulation (last regret = -0.250).
- Player 'UniformOnSome([0, 1, 6, 8])'	was ranked	5 / 6 for this simulation (last regret = -0.200).
- Player 'UniformOnSome([0, 8])'	was ranked	6 / 6 for this simulation (last regret = 0.000).
plots/MP__M6_T100_N20__6_algos is already a directory here...
Plotting the results, and saving the plot to plots/MP__M6_T100_N20__6_algos/main____env1-1_25650343103225960.png ...
Saving to plots/MP__M6_T100_N20__6_algos/main____env1-1_25650343103225960.png ...
 - Plotting the results, and saving the plot to plots/MP__M6_T100_N20__6_algos/main_BestArmPulls____env1-1_25650343103225960.png ...
Saving to plots/MP__M6_T100_N20__6_algos/main_BestArmPulls____env1-1_25650343103225960.png ...
