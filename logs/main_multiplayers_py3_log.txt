Loaded experiments configuration from 'configuration.py' :
configuration = {'players': [<PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fab9ad64c18>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fab74772c50>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fab7469cfd0>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fab746a7e80>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fab746a7cf8>, <PoliciesMultiPlayers.ChildPointer.ChildPointer object at 0x7fab746a7f28>], 'repetitions': 20, 'horizon': 20000, 'averageOn': 0.001, 'collisionModel': <function onlyUniqUserGetsReward at 0x7fab7476d7b8>, 'environment': [{'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}], 'verbosity': 6, 'finalRanksOnAverage': True, 'n_jobs': -1}
plots is already a directory here...
Number of players in the multi-players game: 6
Time horizon: 20000
Number of repetitions: 20
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.85}>
- Adding player #1 = #1<MusicalChair(T0: 1000)> ...
  Using this already created player 'player' = #1<MusicalChair(T0: 1000)> ...
- Adding player #2 = #2<MusicalChair(T0: 1000)> ...
  Using this already created player 'player' = #2<MusicalChair(T0: 1000)> ...
- Adding player #3 = #3<MusicalChair(T0: 1000)> ...
  Using this already created player 'player' = #3<MusicalChair(T0: 1000)> ...
- Adding player #4 = #4<MusicalChair(T0: 1000)> ...
  Using this already created player 'player' = #4<MusicalChair(T0: 1000)> ...
- Adding player #5 = #5<MusicalChair(T0: 1000)> ...
  Using this already created player 'player' = #5<MusicalChair(T0: 1000)> ...
- Adding player #6 = #6<MusicalChair(T0: 1000)> ...
  Using this already created player 'player' = #6<MusicalChair(T0: 1000)> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #1, '#1<MusicalChair(T0: 1000)>'	was ranked	1 / 6 for this simulation (last rewards = 15885.2).
- Player #6, '#6<MusicalChair(T0: 1000)>'	was ranked	2 / 6 for this simulation (last rewards = 15742.1).
- Player #5, '#5<MusicalChair(T0: 1000)>'	was ranked	3 / 6 for this simulation (last rewards = 15578).
- Player #2, '#2<MusicalChair(T0: 1000)>'	was ranked	4 / 6 for this simulation (last rewards = 15512).
- Player #3, '#3<MusicalChair(T0: 1000)>'	was ranked	5 / 6 for this simulation (last rewards = 15495.8).
- Player #4, '#4<MusicalChair(T0: 1000)>'	was ranked	6 / 6 for this simulation (last rewards = 15273.9).
plots/MP__M6_T20000_N20__6_algos is already a directory here...
- Plotting the decentralized rewards, and saving the plot to plots/MP__M6_T20000_N20__6_algos/main____env1-1_7675069554124848724.png ...
Saving to plots/MP__M6_T20000_N20__6_algos/main____env1-1_7675069554124848724.png ...
- Plotting the centralized  rewards, and saving the plot to plots/MP__M6_T20000_N20__6_algos/main_RewardsCentralized____env1-1_7675069554124848724.png ...
Saving to plots/MP__M6_T20000_N20__6_algos/main_RewardsCentralized____env1-1_7675069554124848724.png ...
