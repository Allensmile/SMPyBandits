Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [{'archtype': <class 'Policies.Uniform.Uniform'>, 'params': {}}, {'archtype': <class 'Policies.EpsilonGreedy.EpsilonGreedy'>, 'params': {'epsilon': 0.1}}, {'archtype': <class 'Policies.EpsilonDecreasing.EpsilonDecreasing'>, 'params': {'epsilon': 0.1, 'decreasingRate': 0.005}}, {'archtype': <class 'Policies.EpsilonFirst.EpsilonFirst'>, 'params': {'horizon': 3000, 'epsilon': 0.1}}, {'archtype': <class 'Policies.UCBalpha.UCBalpha'>, 'params': {'alpha': 0.5}}, {'archtype': <class 'Policies.UCBalpha.UCBalpha'>, 'params': {'alpha': 0.1}}]
plots is already a directory here...
Number of policies in this comparaison: 6
Time horizon: 3000
Number of repetitions: 20
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
Number of environments to try: 1

Evaluating environment: <MAB{'maxArm': 0.85, 'nbArms': 17, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]}>
- Adding policy #1 = {'archtype': <class 'Policies.Uniform.Uniform'>, 'params': {}} ...
- Adding policy #2 = {'archtype': <class 'Policies.EpsilonGreedy.EpsilonGreedy'>, 'params': {'epsilon': 0.1}} ...
- Adding policy #3 = {'archtype': <class 'Policies.EpsilonDecreasing.EpsilonDecreasing'>, 'params': {'epsilon': 0.1, 'decreasingRate': 0.005}} ...
- Adding policy #4 = {'archtype': <class 'Policies.EpsilonFirst.EpsilonFirst'>, 'params': {'horizon': 3000, 'epsilon': 0.1}} ...
- Adding policy #5 = {'archtype': <class 'Policies.UCBalpha.UCBalpha'>, 'params': {'alpha': 0.5}} ...
- Adding policy #6 = {'archtype': <class 'Policies.UCBalpha.UCBalpha'>, 'params': {'alpha': 0.1}} ...

- Evaluating policy #1/6: Uniform ...

- Evaluating policy #2/6: EpsilonGreedy ...

- Evaluating policy #3/6: EpsilonDecreasing ...

- Evaluating policy #4/6: EpsilonFirst ...

- Evaluating policy #5/6: UCB1 (alpha: 0.5) ...

- Evaluating policy #6/6: UCB1 (alpha: 0.1) ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'UCB1 (alpha: 0.1)'	was ranked	1 / 6 for this simulation (last regret = 54.95).
- Policy 'UCB1 (alpha: 0.5)'	was ranked	2 / 6 for this simulation (last regret = 85.15).
- Policy 'EpsilonFirst'	was ranked	3 / 6 for this simulation (last regret = 216.8).
- Policy 'EpsilonDecreasing'	was ranked	4 / 6 for this simulation (last regret = 337.1).
- Policy 'EpsilonGreedy'	was ranked	5 / 6 for this simulation (last regret = 644.85).
- Policy 'Uniform'	was ranked	6 / 6 for this simulation (last regret = 1114.8).
plots/T3000_N20__6_algos is already a directory here...
 - Plotting the results, and saving the plot to plots/T3000_N20__6_algos/main____env1-1_1658539449860312249.png ...
  - stdY = [ 0.48989795  0.45825757  0.49749372 ...,  0.4769696   0.4769696   0.5       ]
  - np.shape(stdY) = (3000,)
  - np.min(stdY) = 0.217944947177
  - np.max(stdY) = 0.5
  - stdY = [ 0.21794495  0.35707142  0.4        ...,  0.48989795  0.4330127
  0.49749372]
  - np.shape(stdY) = (3000,)
  - np.min(stdY) = 0.217944947177
  - np.max(stdY) = 0.5
  - stdY = [ 0.35707142  0.35707142  0.49749372 ...,  0.35707142  0.4330127
  0.35707142]
  - np.shape(stdY) = (3000,)
  - np.min(stdY) = 0.0
  - np.max(stdY) = 0.5
  - stdY = [ 0.48989795  0.5         0.49749372 ...,  0.35707142  0.4769696   0.4       ]
  - np.shape(stdY) = (3000,)
  - np.min(stdY) = 0.0
  - np.max(stdY) = 0.5
  - stdY = [ 0.          0.          0.3        ...,  0.3         0.49749372
  0.21794495]
  - np.shape(stdY) = (3000,)
  - np.min(stdY) = 0.0
  - np.max(stdY) = 0.5
  - stdY = [ 0.          0.4         0.48989795 ...,  0.4         0.35707142  0.4       ]
  - np.shape(stdY) = (3000,)
  - np.min(stdY) = 0.0
  - np.max(stdY) = 0.5
Saving to plots/T3000_N20__6_algos/main____env1-1_1658539449860312249.png ...
 - Plotting the results, and saving the plot to plots/T3000_N20__6_algos/main_BestArmPulls____env1-1_1658539449860312249.png ...
Saving to plots/T3000_N20__6_algos/main_BestArmPulls____env1-1_1658539449860312249.png ...
