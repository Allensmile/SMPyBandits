Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 10, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 1, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 0.1, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 0.01, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 0.001, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}]
plots is already a directory here...
Number of algorithms to compare: 11
Number of environments to try: 1
Time horizon: 10000
Number of repetitions: 100

Evaluating environment: <MAB{'nbArms': 9, 'maxArm': 0.81999999999999995, 'arms': [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.78), B(0.8), B(0.82)]}>
policy = {'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}
policy = {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}
policy = {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}
policy = {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}
policy = {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}
policy = {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}
policy = {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 10, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}
policy = {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 1, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}
policy = {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 0.1, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}
policy = {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 0.01, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}
policy = {'params': {'decreaseRate': None, 'one_job_by_children': False, 'update_all_children': True, 'n_jobs': 1, 'learningRate': 0.001, 'children': [{'params': {}, 'archtype': <class 'Policies.UCB.UCB'>}, {'params': {}, 'archtype': <class 'Policies.UCBV.UCBV'>}, {'params': {'temperature': 0.05}, 'archtype': <class 'Policies.Softmax.Softmax'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'verbosity': 0}, 'archtype': <class 'Policies.Aggr.Aggr'>}

- Evaluating policy #1/11: UCB ...

- Evaluating policy #2/11: UCBV ...

- Evaluating policy #3/11: Softmax (temperature:0.05) ...

- Evaluating policy #4/11: Thompson ...

- Evaluating policy #5/11: klUCB ...

- Evaluating policy #6/11: BayesUCB ...

- Evaluating policy #7/11: Aggr (nb:6, rate:10) ...

- Evaluating policy #8/11: Aggr (nb:6, rate:1) ...

- Evaluating policy #9/11: Aggr (nb:6, rate:0.1) ...

- Evaluating policy #10/11: Aggr (nb:6, rate:0.01) ...

- Evaluating policy #11/11: Aggr (nb:6, rate:0.001) ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'BayesUCB'	was ranked	1 / 11 for this simulation (last regret = 300.520).
- Policy 'klUCB'	was ranked	2 / 11 for this simulation (last regret = 308.450).
- Policy 'Aggr (nb:6, rate:0.01)'	was ranked	3 / 11 for this simulation (last regret = 482.280).
- Policy 'UCB'	was ranked	4 / 11 for this simulation (last regret = 488.440).
- Policy 'UCBV'	was ranked	5 / 11 for this simulation (last regret = 534.070).
- Policy 'Aggr (nb:6, rate:1)'	was ranked	6 / 11 for this simulation (last regret = 645.870).
- Policy 'Aggr (nb:6, rate:0.1)'	was ranked	7 / 11 for this simulation (last regret = 677.100).
- Policy 'Aggr (nb:6, rate:10)'	was ranked	8 / 11 for this simulation (last regret = 702.890).
- Policy 'Aggr (nb:6, rate:0.001)'	was ranked	9 / 11 for this simulation (last regret = 857.180).
- Policy 'Thompson'	was ranked	10 / 11 for this simulation (last regret = 916.880).
- Policy 'Softmax (temperature:0.05)'	was ranked	11 / 11 for this simulation (last regret = 1781.080).
Plotting the results, and saving the plot to plots/T10000_N100__11_algos/main____env1-1_8411748683231729074.png ...
Using color b for policy number #1/11 and called UCB...
Using color g for policy number #2/11 and called UCBV...
Using color r for policy number #3/11 and called Softmax (temperature:0.05)...
Using color c for policy number #4/11 and called Thompson...
Using color m for policy number #5/11 and called klUCB...
Using color y for policy number #6/11 and called BayesUCB...
Using color k for policy number #7/11 and called Aggr (nb:6, rate:10)...
Using color orange for policy number #8/11 and called Aggr (nb:6, rate:1)...
Using color purple for policy number #9/11 and called Aggr (nb:6, rate:0.1)...
Using color darkgreen for policy number #10/11 and called Aggr (nb:6, rate:0.01)...
Using color darkblue for policy number #11/11 and called Aggr (nb:6, rate:0.001)...
Saving to plots/T10000_N100__11_algos/main____env1-1_8411748683231729074.png ...
