Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [<Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5ba8>, <Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5e48>, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 30000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'learningRate': 0.01, 'horizon': 30000, 'update_all_children': False, 'decreaseRate': 'auto', 'children': [<Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5ba8>, <Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5e48>, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 30000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>}]
plots/ is already a directory here...
Number of policies in this comparaison: 11
Time horizon: 30000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
 - with 'arms' = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]
 - with 'nbArms' = 9
 - with 'maxArm' = 0.9
Number of environments to try: 1

Evaluating environment: <MAB{'maxArm': 0.90000000000000002, 'nbArms': 9, 'arms': [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]}>
- Adding policy #1 = TakeFixedArm(8) ...
  Using this already created policy 'self.cfg['policies'][0]' = TakeFixedArm(8) ...
- Adding policy #2 = TakeFixedArm(7) ...
  Using this already created policy 'self.cfg['policies'][1]' = TakeFixedArm(7) ...
- Adding policy #3 = {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][2]' = {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>} ...
- Adding policy #4 = {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][3]' = {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>} ...
- Adding policy #5 = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][4]' = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
- Adding policy #6 = {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][5]' = {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
- Adding policy #7 = {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][6]' = {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>} ...
- Adding policy #8 = {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][7]' = {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
- Adding policy #9 = {'params': {'horizon': 30000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][8]' = {'params': {'horizon': 30000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
- Adding policy #10 = {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][9]' = {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
- Adding policy #11 = {'params': {'learningRate': 0.01, 'horizon': 30000, 'update_all_children': False, 'decreaseRate': 'auto', 'children': [<Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5ba8>, <Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5e48>, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 30000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][10]' = {'params': {'learningRate': 0.01, 'horizon': 30000, 'update_all_children': False, 'decreaseRate': 'auto', 'children': [<Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5ba8>, <Policies.TakeFixedArm.TakeFixedArm object at 0x7f717f8f5e48>, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 30000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Using this already created player 'children[0]' = TakeFixedArm(8) ...
  Using this already created player 'children[1]' = TakeFixedArm(7) ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[6]' = {'params': {}, 'archtype': <class 'Policies.klUCB.klUCB'>} ...
  Creating this child player from a dictionnary 'children[7]' = {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[8]' = {'params': {'horizon': 30000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
  Creating this child player from a dictionnary 'children[9]' = {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...

- Evaluating policy #1/11: TakeFixedArm(8) ...

- Evaluating policy #2/11: TakeFixedArm(7) ...

- Evaluating policy #3/11: Softmax(decreasing) ...

- Evaluating policy #4/11: UCBopt ...

- Evaluating policy #5/11: MOSS ...

- Evaluating policy #6/11: Thompson ...

- Evaluating policy #7/11: klUCB ...

- Evaluating policy #8/11: klUCBPlus ...

- Evaluating policy #9/11: klUCBHPlus ...

- Evaluating policy #10/11: BayesUCB ...

- Evaluating policy #11/11: Aggr(nb: 10, rate: 0.01, dRate: auto) ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'TakeFixedArm(8)'	was ranked	1 / 11 for this simulation (last regret = -3.35).
- Policy 'klUCBPlus'	was ranked	2 / 11 for this simulation (last regret = 15.9).
- Policy 'BayesUCB'	was ranked	3 / 11 for this simulation (last regret = 28.9).
- Policy 'klUCB'	was ranked	4 / 11 for this simulation (last regret = 37.9).
- Policy 'Thompson'	was ranked	5 / 11 for this simulation (last regret = 44.4).
- Policy 'Softmax(decreasing)'	was ranked	6 / 11 for this simulation (last regret = 50.65).
- Policy 'Aggr(nb: 10, rate: 0.01, dRate: auto)'	was ranked	7 / 11 for this simulation (last regret = 79.4).
- Policy 'klUCBHPlus'	was ranked	8 / 11 for this simulation (last regret = 98.9).
- Policy 'MOSS'	was ranked	9 / 11 for this simulation (last regret = 98.9).
- Policy 'UCBopt'	was ranked	10 / 11 for this simulation (last regret = 101.9).
- Policy 'TakeFixedArm(7)'	was ranked	11 / 11 for this simulation (last regret = 2973.4).
plots/T30000_N4__11_algos is already a directory here...
