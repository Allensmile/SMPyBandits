 - Setting dpi of all figures to 110 ...
 - Setting 'figsize' of all figures to (19.8, 10.8) ...
Info: Using the regular tqdm() decorator ...
Info: numba.jit seems to be available.
Info: numba.jit seems to be available.
Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [{'params': {'alpha': 4}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>}, {'params': {'alpha': 1}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>}, {'params': {'alpha': 0.5}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>}, {'params': {'alpha': 0.05}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {'genuine': True}, 'archtype': <class 'Policies.DMED.DMED'>}, {'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'posterior': <class 'Policies.Posterior.Gauss.Gauss'>}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCB.klUCB'>}, {'params': {'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 10000, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {'horizon': 10000, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlusPlus.klUCBPlusPlus'>}, {'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}]
plots/ is already a directory here...
Number of policies in this comparison: 13
Time horizon: 10000
Number of repetitions: 4
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
 - with 'arms' = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]
 - with 'means' = [ 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9]
 - with 'nbArms' = 9
 - with 'maxArm' = 0.9
 - with 'minArm' = 0.1

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 7.52 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
 - with 'arms' represented as: $[B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)^*]$
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 9, arms: [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)], minArm: 0.1, maxArm: 0.9)
- Adding policy #1 = {'params': {'alpha': 4}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][0]' = {'params': {'alpha': 4}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
- Adding policy #2 = {'params': {'alpha': 1}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][1]' = {'params': {'alpha': 1}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
- Adding policy #3 = {'params': {'alpha': 0.5}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][2]' = {'params': {'alpha': 0.5}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
- Adding policy #4 = {'params': {'alpha': 0.05}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][3]' = {'params': {'alpha': 0.05}, 'archtype': <class 'Policies.UCBalpha.UCBalpha'>} ...
- Adding policy #5 = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][4]' = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
- Adding policy #6 = {'params': {'genuine': True}, 'archtype': <class 'Policies.DMED.DMED'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][5]' = {'params': {'genuine': True}, 'archtype': <class 'Policies.DMED.DMED'>} ...
- Adding policy #7 = {'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][6]' = {'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
- Adding policy #8 = {'params': {'posterior': <class 'Policies.Posterior.Gauss.Gauss'>}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][7]' = {'params': {'posterior': <class 'Policies.Posterior.Gauss.Gauss'>}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
- Adding policy #9 = {'params': {'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCB.klUCB'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][8]' = {'params': {'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCB.klUCB'>} ...
- Adding policy #10 = {'params': {'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][9]' = {'params': {'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
- Adding policy #11 = {'params': {'horizon': 10000, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][10]' = {'params': {'horizon': 10000, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
- Adding policy #12 = {'params': {'horizon': 10000, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlusPlus.klUCBPlusPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][11]' = {'params': {'horizon': 10000, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlusPlus.klUCBPlusPlus'>} ...
- Adding policy #13 = {'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][12]' = {'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...

- Evaluating policy #1/13: UCB($\alpha=4$) ...

Estimated order by the policy UCB($\alpha=4$) after 10000 steps: [1 2 0 4 5 3 6 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.65% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.91% (relative success)...
  ==> Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==> Mean distance from optimal ordering: 89.39% (relative success)...

- Evaluating policy #2/13: UCB($\alpha=1$) ...

Estimated order by the policy UCB($\alpha=1$) after 10000 steps: [0 1 3 2 5 6 4 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 85.19% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.82% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.98% (relative success)...
  ==> Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==> Mean distance from optimal ordering: 90.69% (relative success)...

- Evaluating policy #3/13: UCB($\alpha=0.5$) ...

Estimated order by the policy UCB($\alpha=0.5$) after 10000 steps: [0 1 3 4 7 2 6 5 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 75.31% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.04% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 84.94% (relative success)...

- Evaluating policy #4/13: UCB($\alpha=0.05$) ...

Estimated order by the policy UCB($\alpha=0.05$) after 10000 steps: [1 2 6 3 0 4 5 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 97.82% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.42% (relative success)...
  ==> Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==> Mean distance from optimal ordering: 85.60% (relative success)...

- Evaluating policy #5/13: MOSS ...

Estimated order by the policy MOSS after 10000 steps: [0 3 5 1 2 4 6 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 75.31% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.33% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.28% (relative success)...
  ==> Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==> Mean distance from optimal ordering: 87.92% (relative success)...

- Evaluating policy #6/13: DMED+(Bern) ...

- Evaluating policy #7/13: Thompson ...

Estimated order by the policy Thompson after 10000 steps: [0 2 1 5 3 6 4 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.65% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.91% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 86.62% (relative success)...

- Evaluating policy #8/13: Thompson(Gauss) ...

Estimated order by the policy Thompson(Gauss) after 10000 steps: [0 3 2 1 5 7 6 4 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 75.31% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 97.82% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.28% (relative success)...
  ==> Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==> Mean distance from optimal ordering: 81.99% (relative success)...

- Evaluating policy #9/13: KL-UCB(Bern) ...

Estimated order by the policy KL-UCB(Bern) after 10000 steps: [0 5 4 6 3 7 1 2 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 45.68% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 59.58% (relative success)...
  ==> Spearman    distance from optimal ordering: 56.72% (relative success)...
  ==> Gestalt     distance from optimal ordering: 44.44% (relative success)...
  ==> Mean distance from optimal ordering: 51.60% (relative success)...

- Evaluating policy #10/13: KL-UCB+(Bern) ...

Estimated order by the policy KL-UCB+(Bern) after 10000 steps: [0 3 4 5 6 1 7 2 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 55.56% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 93.94% (relative success)...
  ==> Spearman    distance from optimal ordering: 84.56% (relative success)...
  ==> Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==> Mean distance from optimal ordering: 77.96% (relative success)...

- Evaluating policy #11/13: KL-UCB-H+(Bern) ...

Estimated order by the policy KL-UCB-H+(Bern) after 10000 steps: [3 2 4 1 5 0 7 6 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 60.49% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 90.47% (relative success)...
  ==> Spearman    distance from optimal ordering: 92.31% (relative success)...
  ==> Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==> Mean distance from optimal ordering: 74.71% (relative success)...

- Evaluating policy #12/13: KL-UCB++(Bern) ...

Estimated order by the policy KL-UCB++(Bern) after 10000 steps: [0 3 1 2 4 5 7 6 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 85.19% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.82% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.98% (relative success)...
  ==> Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==> Mean distance from optimal ordering: 90.69% (relative success)...

- Evaluating policy #13/13: BayesUCB ...

Estimated order by the policy BayesUCB after 10000 steps: [5 0 1 3 2 7 4 6 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 65.43% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 96.29% (relative success)...
  ==> Spearman    distance from optimal ordering: 95.01% (relative success)...
  ==> Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==> Mean distance from optimal ordering: 78.07% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'KL-UCB++(Bern)'	was ranked	1 / 13 for this simulation (last regret = 21.4).
- Policy 'BayesUCB'	was ranked	2 / 13 for this simulation (last regret = 22.15).
- Policy 'KL-UCB(Bern)'	was ranked	3 / 13 for this simulation (last regret = 50.65).
- Policy 'Thompson'	was ranked	4 / 13 for this simulation (last regret = 52.15).
- Policy 'KL-UCB-H+(Bern)'	was ranked	5 / 13 for this simulation (last regret = 54.15).
- Policy 'DMED+(Bern)'	was ranked	6 / 13 for this simulation (last regret = 54.9).
- Policy 'KL-UCB+(Bern)'	was ranked	7 / 13 for this simulation (last regret = 62.65).
- Policy 'UCB($\alpha=0.5$)'	was ranked	8 / 13 for this simulation (last regret = 64.9).
- Policy 'MOSS'	was ranked	9 / 13 for this simulation (last regret = 87.15).
- Policy 'UCB($\alpha=1$)'	was ranked	10 / 13 for this simulation (last regret = 126.9).
- Policy 'UCB($\alpha=0.05$)'	was ranked	11 / 13 for this simulation (last regret = 258.15).
- Policy 'UCB($\alpha=4$)'	was ranked	12 / 13 for this simulation (last regret = 347.4).
- Policy 'Thompson(Gauss)'	was ranked	13 / 13 for this simulation (last regret = 1124.65).
Saving the Evaluator 'evaluation' objet to plots/T10000_N4__13_algos/main____env1-1_6352887485126430344.pickle ...
 - Plotting the cumulative rewards, and saving the plot to plots/T10000_N4__13_algos/main____env1-1_6352887485126430344 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 7.52 for 1-player problem... 
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
Saving figure with format png, to file 'plots/T10000_N4__13_algos/main____env1-1_6352887485126430344.png'...
       Saved! 'plots/T10000_N4__13_algos/main____env1-1_6352887485126430344.png' created of size '223241b', at 'Thu May 18 19:01:41 2017' ...
Saving figure with format pdf, to file 'plots/T10000_N4__13_algos/main____env1-1_6352887485126430344.pdf'...
       Saved! 'plots/T10000_N4__13_algos/main____env1-1_6352887485126430344.pdf' created of size '405023b', at 'Thu May 18 19:01:41 2017' ...
Saving figure with format svg, to file 'plots/T10000_N4__13_algos/main____env1-1_6352887485126430344.svg'...
       Saved! 'plots/T10000_N4__13_algos/main____env1-1_6352887485126430344.svg' created of size '1233621b', at 'Thu May 18 19:01:42 2017' ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 7.52 for 1-player problem... 
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
Saving figure with format png, to file 'plots/T10000_N4__13_algos/main_semilogx____env1-1_6352887485126430344.png'...
       Saved! 'plots/T10000_N4__13_algos/main_semilogx____env1-1_6352887485126430344.png' created of size '208397b', at 'Thu May 18 19:01:43 2017' ...
Saving figure with format pdf, to file 'plots/T10000_N4__13_algos/main_semilogx____env1-1_6352887485126430344.pdf'...
       Saved! 'plots/T10000_N4__13_algos/main_semilogx____env1-1_6352887485126430344.pdf' created of size '423412b', at 'Thu May 18 19:01:43 2017' ...
Saving figure with format svg, to file 'plots/T10000_N4__13_algos/main_semilogx____env1-1_6352887485126430344.svg'...
       Saved! 'plots/T10000_N4__13_algos/main_semilogx____env1-1_6352887485126430344.svg' created of size '1303469b', at 'Thu May 18 19:01:43 2017' ...
 - Plotting the mean rewards, and saving the plot to plots/T10000_N4__13_algos/main_MeanRewards____env1-1_6352887485126430344 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 7.52 for 1-player problem... 
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
Saving figure with format png, to file 'plots/T10000_N4__13_algos/main_MeanRewards____env1-1_6352887485126430344.png'...
       Saved! 'plots/T10000_N4__13_algos/main_MeanRewards____env1-1_6352887485126430344.png' created of size '212953b', at 'Thu May 18 19:01:45 2017' ...
Saving figure with format pdf, to file 'plots/T10000_N4__13_algos/main_MeanRewards____env1-1_6352887485126430344.pdf'...
       Saved! 'plots/T10000_N4__13_algos/main_MeanRewards____env1-1_6352887485126430344.pdf' created of size '285927b', at 'Thu May 18 19:01:45 2017' ...
Saving figure with format svg, to file 'plots/T10000_N4__13_algos/main_MeanRewards____env1-1_6352887485126430344.svg'...
       Saved! 'plots/T10000_N4__13_algos/main_MeanRewards____env1-1_6352887485126430344.svg' created of size '746252b', at 'Thu May 18 19:01:45 2017' ...
 - Plotting the results, and saving the plot to plots/T10000_N4__13_algos/main_BestArmPulls____env1-1_6352887485126430344 ...
Saving figure with format png, to file 'plots/T10000_N4__13_algos/main_BestArmPulls____env1-1_6352887485126430344.png'...
       Saved! 'plots/T10000_N4__13_algos/main_BestArmPulls____env1-1_6352887485126430344.png' created of size '254721b', at 'Thu May 18 19:01:46 2017' ...
Saving figure with format pdf, to file 'plots/T10000_N4__13_algos/main_BestArmPulls____env1-1_6352887485126430344.pdf'...
       Saved! 'plots/T10000_N4__13_algos/main_BestArmPulls____env1-1_6352887485126430344.pdf' created of size '105914b', at 'Thu May 18 19:01:47 2017' ...
Saving figure with format svg, to file 'plots/T10000_N4__13_algos/main_BestArmPulls____env1-1_6352887485126430344.svg'...
       Saved! 'plots/T10000_N4__13_algos/main_BestArmPulls____env1-1_6352887485126430344.svg' created of size '275671b', at 'Thu May 18 19:01:47 2017' ...


==> To see the figures, do :
eog plots/T10000_N4__13_algos/main*6352887485126430344.png
Done for simulations main.py ...
