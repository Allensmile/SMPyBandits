Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [{'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 10000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'children': [{'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 10000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'update_all_children': False, 'decreaseRate': 5000.0, 'learningRate': 0.01}, 'archtype': <class 'Policies.Aggr.Aggr'>}]
plots/ is already a directory here...
Number of policies in this comparaison: 8
Time horizon: 10000
Number of repetitions: 20
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.2, 0.5]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.2, 0.5]
 - with 'arms' = [B(0.001), B(0.001), B(0.001), B(0.001), B(0.005), B(0.005), B(0.005), B(0.005), B(0.01), B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.1), B(0.1), B(0.2), B(0.5)]
 - with 'nbArms' = 34
 - with 'maxArm' = 0.5
Number of environments to try: 1

Evaluating environment: <MAB{'arms': [B(0.001), B(0.001), B(0.001), B(0.001), B(0.005), B(0.005), B(0.005), B(0.005), B(0.01), B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.05), B(0.1), B(0.1), B(0.2), B(0.5)], 'nbArms': 34, 'maxArm': 0.5}>
- Adding policy #1 = {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][0]' = {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>} ...
- Adding policy #2 = {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][1]' = {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>} ...
- Adding policy #3 = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][2]' = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
- Adding policy #4 = {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][3]' = {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
- Adding policy #5 = {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][4]' = {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
- Adding policy #6 = {'params': {'horizon': 10000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][5]' = {'params': {'horizon': 10000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
- Adding policy #7 = {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][6]' = {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
- Adding policy #8 = {'params': {'children': [{'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 10000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'update_all_children': False, 'decreaseRate': 5000.0, 'learningRate': 0.01}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][7]' = {'params': {'children': [{'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>}, {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>}, {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>}, {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'horizon': 10000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>}, {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}], 'update_all_children': False, 'decreaseRate': 5000.0, 'learningRate': 0.01}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this child player from a dictionnary 'children[0]' = {'params': {}, 'archtype': <class 'Policies.UCBopt.UCBopt'>} ...
  Creating this child player from a dictionnary 'children[1]' = {'params': {}, 'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>} ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {}, 'archtype': <class 'Policies.MOSS.MOSS'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {'horizon': 10000}, 'archtype': <class 'Policies.klUCBHPlus.klUCBHPlus'>} ...
  Creating this child player from a dictionnary 'children[6]' = {'params': {}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...

- Evaluating policy #1/8: UCBopt ...

- Evaluating policy #2/8: Softmax(decreasing) ...

- Evaluating policy #3/8: MOSS ...

- Evaluating policy #4/8: Thompson ...

- Evaluating policy #5/8: klUCBPlus ...

- Evaluating policy #6/8: klUCBHPlus ...

- Evaluating policy #7/8: BayesUCB ...

- Evaluating policy #8/8: Aggr(nb: 7, rate: 0.01) ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'Softmax(decreasing)'	was ranked	1 / 8 for this simulation (last regret = 33.4).
- Policy 'klUCBPlus'	was ranked	2 / 8 for this simulation (last regret = 183.75).
- Policy 'klUCBHPlus'	was ranked	3 / 8 for this simulation (last regret = 191.45).
- Policy 'BayesUCB'	was ranked	4 / 8 for this simulation (last regret = 199.1).
- Policy 'Thompson'	was ranked	5 / 8 for this simulation (last regret = 216.75).
- Policy 'MOSS'	was ranked	6 / 8 for this simulation (last regret = 226.7).
- Policy 'Aggr(nb: 7, rate: 0.01)'	was ranked	7 / 8 for this simulation (last regret = 238.5).
- Policy 'UCBopt'	was ranked	8 / 8 for this simulation (last regret = 298).
