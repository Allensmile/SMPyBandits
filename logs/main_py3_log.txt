Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [{'archtype': <class 'Policies.UCBplus.UCBplus'>, 'params': {}}, {'archtype': <class 'Policies.UCBopt.UCBopt'>, 'params': {}}, {'archtype': <class 'Policies.UCBtuned.UCBtuned'>, 'params': {}}, {'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>, 'params': {}}, {'archtype': <class 'Policies.MOSS.MOSS'>, 'params': {}}, {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {}}, {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {}}, {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {}}]
plots/ is already a directory here...
Number of policies in this comparaison: 8
Time horizon: 10000
Number of repetitions: 50
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.78, 0.8, 0.82]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.78, 0.8, 0.82]
 - with 'arms' = [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.78), B(0.8), B(0.82)]
 - with 'nbArms' = 9
 - with 'maxArm' = 0.82
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 9, 'maxArm': 0.82, 'arms': [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.78), B(0.8), B(0.82)]}>
- Adding policy #1 = {'archtype': <class 'Policies.UCBplus.UCBplus'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][0]' = {'archtype': <class 'Policies.UCBplus.UCBplus'>, 'params': {}} ...
- Adding policy #2 = {'archtype': <class 'Policies.UCBopt.UCBopt'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][1]' = {'archtype': <class 'Policies.UCBopt.UCBopt'>, 'params': {}} ...
- Adding policy #3 = {'archtype': <class 'Policies.UCBtuned.UCBtuned'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][2]' = {'archtype': <class 'Policies.UCBtuned.UCBtuned'>, 'params': {}} ...
- Adding policy #4 = {'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][3]' = {'archtype': <class 'Policies.Softmax.SoftmaxDecreasing'>, 'params': {}} ...
- Adding policy #5 = {'archtype': <class 'Policies.MOSS.MOSS'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][4]' = {'archtype': <class 'Policies.MOSS.MOSS'>, 'params': {}} ...
- Adding policy #6 = {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][5]' = {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {}} ...
- Adding policy #7 = {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][6]' = {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {}} ...
- Adding policy #8 = {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][7]' = {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {}} ...

- Evaluating policy #1/8: UCBplus ...

- Evaluating policy #2/8: UCBopt ...

- Evaluating policy #3/8: UCBtuned ...

- Evaluating policy #4/8: Softmax(decreasing) ...

- Evaluating policy #5/8: MOSS ...

- Evaluating policy #6/8: Thompson ...

- Evaluating policy #7/8: klUCB ...

- Evaluating policy #8/8: BayesUCB ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'Thompson'	was ranked	1 / 8 for this simulation (last regret = 82.5).
- Policy 'BayesUCB'	was ranked	2 / 8 for this simulation (last regret = 95.86).
- Policy 'MOSS'	was ranked	3 / 8 for this simulation (last regret = 98.16).
- Policy 'Softmax(decreasing)'	was ranked	4 / 8 for this simulation (last regret = 100.68).
- Policy 'UCBplus'	was ranked	5 / 8 for this simulation (last regret = 107.7).
- Policy 'klUCB'	was ranked	6 / 8 for this simulation (last regret = 110.02).
- Policy 'UCBopt'	was ranked	7 / 8 for this simulation (last regret = 136.74).
- Policy 'UCBtuned'	was ranked	8 / 8 for this simulation (last regret = 177.84).
plots/T10000_N50__8_algos is already a directory here...
