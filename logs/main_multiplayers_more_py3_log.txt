 - Setting dpi of all figures to 110 ...
 - Setting 'figsize' of all figures to (19.8, 10.8) ...
Info: Using the regular tqdm() decorator ...
Info: numba.jit seems to be available.
Info: numba.jit seems to be available.
 - One new child, of index 0, and class #1<CentralizedMultiplePlay(BayesUCB)> ...
 - One new child, of index 1, and class #2<CentralizedMultiplePlay(BayesUCB)> ...
 - One new child, of index 2, and class #3<CentralizedMultiplePlay(BayesUCB)> ...
Loaded experiments configuration from 'configuration.py' :
configuration = {'environment': [{'params': [0.3, 0.4, 0.5, 0.6, 0.7], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}], 'collisionModel': <function onlyUniqUserGetsReward at 0x7f841bce02f0>, 'delta_t_save': 1, 'repetitions': 50, 'horizon': 10000, 'finalRanksOnAverage': True, 'averageOn': 0.001, 'successive_players': [[CentralizedMultiplePlay(BayesUCB), CentralizedMultiplePlay(BayesUCB), CentralizedMultiplePlay(BayesUCB)], [Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB)], [rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB)], [rhoEst(BayesUCB), rhoEst(BayesUCB), rhoEst(BayesUCB)], [rhoLearn(BayesUCB), rhoLearn(BayesUCB), rhoLearn(BayesUCB)]], 'n_jobs': 4, 'verbosity': 6, 'players': [rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB)]}
plots/ is already a directory here...



Considering the list of players :
 [CentralizedMultiplePlay(BayesUCB), CentralizedMultiplePlay(BayesUCB), CentralizedMultiplePlay(BayesUCB)]
Number of players in the multi-players game: 3
Time horizon: 10000
Number of repetitions: 50
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.3, 0.4, 0.5, 0.6, 0.7], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.3, 0.4, 0.5, 0.6, 0.7]
 - with 'arms' = [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)]
 - with 'nbArms' = 5
 - with 'maxArm' = 0.7
 - with 'minArm' = 0.3

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 5, arms: [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)], minArm: 0.3, maxArm: 0.7)
- Adding player #1 = #1<CentralizedMultiplePlay(BayesUCB)> ...
  Using this already created player 'player' = #1<CentralizedMultiplePlay(BayesUCB)> ...
- Adding player #2 = #2<CentralizedMultiplePlay(BayesUCB)> ...
  Using this already created player 'player' = #2<CentralizedMultiplePlay(BayesUCB)> ...
- Adding player #3 = #3<CentralizedMultiplePlay(BayesUCB)> ...
  Using this already created player 'player' = #3<CentralizedMultiplePlay(BayesUCB)> ...

Estimated order by the policy #1<CentralizedMultiplePlay(BayesUCB)> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...

Estimated order by the policy #2<CentralizedMultiplePlay(BayesUCB)> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...

Estimated order by the policy #3<CentralizedMultiplePlay(BayesUCB)> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #1, '#1<CentralizedMultiplePlay(BayesUCB)>'	was ranked	1 / 3 for this simulation (last rewards = 6072.34).
- Player #3, '#3<CentralizedMultiplePlay(BayesUCB)>'	was ranked	2 / 3 for this simulation (last rewards = 5959.34).
- Player #2, '#2<CentralizedMultiplePlay(BayesUCB)>'	was ranked	3 / 3 for this simulation (last rewards = 5908.98).
plots/MP__M3_T10000_N50__3_algos is already a directory here...



Considering the list of players :
 [Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB)]
Number of players in the multi-players game: 3
Time horizon: 10000
Number of repetitions: 50
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.3, 0.4, 0.5, 0.6, 0.7], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.3, 0.4, 0.5, 0.6, 0.7]
 - with 'arms' = [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)]
 - with 'nbArms' = 5
 - with 'maxArm' = 0.7
 - with 'minArm' = 0.3

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 5, arms: [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)], minArm: 0.3, maxArm: 0.7)
- Adding player #1 = #1<Selfish, BayesUCB> ...
  Using this already created player 'player' = #1<Selfish, BayesUCB> ...
- Adding player #2 = #2<Selfish, BayesUCB> ...
  Using this already created player 'player' = #2<Selfish, BayesUCB> ...
- Adding player #3 = #3<Selfish, BayesUCB> ...
  Using this already created player 'player' = #3<Selfish, BayesUCB> ...

Estimated order by the policy #1<Selfish, BayesUCB> after 10000 steps: [4 0 3 1 2] ...
  ==> Optimal arm identification: 83.33% (relative success)...
  ==> Manhattan   distance from optimal ordering: 20.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 37.58% (relative success)...
  ==> Spearman    distance from optimal ordering: 37.62% (relative success)...
  ==> Gestalt     distance from optimal ordering: 60.00% (relative success)...
  ==> Mean distance from optimal ordering: 38.80% (relative success)...

Estimated order by the policy #2<Selfish, BayesUCB> after 10000 steps: [2 1 3 0 4] ...
  ==> Optimal arm identification: 88.89% (relative success)...
  ==> Manhattan   distance from optimal ordering: 52.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 37.58% (relative success)...
  ==> Spearman    distance from optimal ordering: 37.62% (relative success)...
  ==> Gestalt     distance from optimal ordering: 60.00% (relative success)...
  ==> Mean distance from optimal ordering: 46.80% (relative success)...

Estimated order by the policy #3<Selfish, BayesUCB> after 10000 steps: [4 2 1 0 3] ...
  ==> Optimal arm identification: 72.22% (relative success)...
  ==> Manhattan   distance from optimal ordering: 20.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 67.28% (relative success)...
  ==> Spearman    distance from optimal ordering: 49.54% (relative success)...
  ==> Gestalt     distance from optimal ordering: 20.00% (relative success)...
  ==> Mean distance from optimal ordering: 39.20% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #3, '#3<Selfish, BayesUCB>'	was ranked	1 / 3 for this simulation (last rewards = 6022.92).
- Player #1, '#1<Selfish, BayesUCB>'	was ranked	2 / 3 for this simulation (last rewards = 5921.88).
- Player #2, '#2<Selfish, BayesUCB>'	was ranked	3 / 3 for this simulation (last rewards = 5882.3).
plots/MP__M3_T10000_N50__3_algos is already a directory here...



Considering the list of players :
 [rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB)]
Number of players in the multi-players game: 3
Time horizon: 10000
Number of repetitions: 50
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.3, 0.4, 0.5, 0.6, 0.7], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.3, 0.4, 0.5, 0.6, 0.7]
 - with 'arms' = [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)]
 - with 'nbArms' = 5
 - with 'maxArm' = 0.7
 - with 'minArm' = 0.3

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 5, arms: [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)], minArm: 0.3, maxArm: 0.7)
- Adding player #1 = #1<$\rho^{\mathrm{Rand}}$, BayesUCB> ...
  Using this already created player 'player' = #1<$\rho^{\mathrm{Rand}}$, BayesUCB> ...
- Adding player #2 = #2<$\rho^{\mathrm{Rand}}$, BayesUCB> ...
  Using this already created player 'player' = #2<$\rho^{\mathrm{Rand}}$, BayesUCB> ...
- Adding player #3 = #3<$\rho^{\mathrm{Rand}}$, BayesUCB> ...
  Using this already created player 'player' = #3<$\rho^{\mathrm{Rand}}$, BayesUCB> ...

Estimated order by the policy #1<$\rho^{\mathrm{Rand}}$, BayesUCB, rank:1> after 10000 steps: [3 2 1 0 4] ...
  ==> Optimal arm identification: 77.78% (relative success)...
  ==> Manhattan   distance from optimal ordering: 36.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 37.58% (relative success)...
  ==> Spearman    distance from optimal ordering: 0.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 40.00% (relative success)...
  ==> Mean distance from optimal ordering: 28.39% (relative success)...

Estimated order by the policy #2<$\rho^{\mathrm{Rand}}$, BayesUCB, rank:3> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...

Estimated order by the policy #3<$\rho^{\mathrm{Rand}}$, BayesUCB, rank:2> after 10000 steps: [2 1 0 3 4] ...
  ==> Optimal arm identification: 88.89% (relative success)...
  ==> Manhattan   distance from optimal ordering: 68.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 67.28% (relative success)...
  ==> Spearman    distance from optimal ordering: 71.52% (relative success)...
  ==> Gestalt     distance from optimal ordering: 60.00% (relative success)...
  ==> Mean distance from optimal ordering: 66.70% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #2, '#2<$\rho^{\mathrm{Rand}}$, BayesUCB>'	was ranked	1 / 3 for this simulation (last rewards = 5943.22).
- Player #1, '#1<$\rho^{\mathrm{Rand}}$, BayesUCB>'	was ranked	2 / 3 for this simulation (last rewards = 5937.4).
- Player #3, '#3<$\rho^{\mathrm{Rand}}$, BayesUCB>'	was ranked	3 / 3 for this simulation (last rewards = 5758.66).
plots/MP__M3_T10000_N50__3_algos is already a directory here...



Considering the list of players :
 [rhoEst(BayesUCB), rhoEst(BayesUCB), rhoEst(BayesUCB)]
Number of players in the multi-players game: 3
Time horizon: 10000
Number of repetitions: 50
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.3, 0.4, 0.5, 0.6, 0.7], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.3, 0.4, 0.5, 0.6, 0.7]
 - with 'arms' = [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)]
 - with 'nbArms' = 5
 - with 'maxArm' = 0.7
 - with 'minArm' = 0.3

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 5, arms: [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)], minArm: 0.3, maxArm: 0.7)
- Adding player #1 = #1<$\rho^{\mathrm{Est}}$, BayesUCB> ...
  Using this already created player 'player' = #1<$\rho^{\mathrm{Est}}$, BayesUCB> ...
- Adding player #2 = #2<$\rho^{\mathrm{Est}}$, BayesUCB> ...
  Using this already created player 'player' = #2<$\rho^{\mathrm{Est}}$, BayesUCB> ...
- Adding player #3 = #3<$\rho^{\mathrm{Est}}$, BayesUCB> ...
  Using this already created player 'player' = #3<$\rho^{\mathrm{Est}}$, BayesUCB> ...

Estimated order by the policy #1<$\rho^{\mathrm{Est}}$, BayesUCB, rank:2> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...

Estimated order by the policy #2<$\rho^{\mathrm{Est}}$, BayesUCB, rank:1> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...

Estimated order by the policy #3<$\rho^{\mathrm{Est}}$, BayesUCB, rank:1> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #1, '#1<$\rho^{\mathrm{Est}}$, BayesUCB>'	was ranked	1 / 3 for this simulation (last rewards = 1960.78).
- Player #3, '#3<$\rho^{\mathrm{Est}}$, BayesUCB>'	was ranked	2 / 3 for this simulation (last rewards = 1821.56).
- Player #2, '#2<$\rho^{\mathrm{Est}}$, BayesUCB>'	was ranked	3 / 3 for this simulation (last rewards = 1806.78).
plots/MP__M3_T10000_N50__3_algos is already a directory here...



Considering the list of players :
 [rhoLearn(BayesUCB), rhoLearn(BayesUCB), rhoLearn(BayesUCB)]
Number of players in the multi-players game: 3
Time horizon: 10000
Number of repetitions: 50
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.3, 0.4, 0.5, 0.6, 0.7], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.3, 0.4, 0.5, 0.6, 0.7]
 - with 'arms' = [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)]
 - with 'nbArms' = 5
 - with 'maxArm' = 0.7
 - with 'minArm' = 0.3

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 5, arms: [B(0.3), B(0.4), B(0.5), B(0.6), B(0.7)], minArm: 0.3, maxArm: 0.7)
- Adding player #1 = #1<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB> ...
  Using this already created player 'player' = #1<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB> ...
- Adding player #2 = #2<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB> ...
  Using this already created player 'player' = #2<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB> ...
- Adding player #3 = #3<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB> ...
  Using this already created player 'player' = #3<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB> ...

Estimated order by the policy #1<$\rho^{\mathrm{Learn}}$, BayesUCB, rank: 3 ~ BayesUCB> after 10000 steps: [0 1 3 4 2] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 68.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 85.84% (relative success)...
  ==> Spearman    distance from optimal ordering: 81.19% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 78.76% (relative success)...

Estimated order by the policy #2<$\rho^{\mathrm{Learn}}$, BayesUCB, rank: 3 ~ BayesUCB> after 10000 steps: [1 0 2 3 4] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 84.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 95.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 96.26% (relative success)...
  ==> Gestalt     distance from optimal ordering: 80.00% (relative success)...
  ==> Mean distance from optimal ordering: 88.81% (relative success)...

Estimated order by the policy #3<$\rho^{\mathrm{Learn}}$, BayesUCB, rank: 2 ~ BayesUCB> after 10000 steps: [1 0 4 2 3] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 52.00% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 67.28% (relative success)...
  ==> Spearman    distance from optimal ordering: 71.52% (relative success)...
  ==> Gestalt     distance from optimal ordering: 60.00% (relative success)...
  ==> Mean distance from optimal ordering: 62.70% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #3, '#3<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB>'	was ranked	1 / 3 for this simulation (last rewards = 5568.54).
- Player #1, '#1<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB>'	was ranked	2 / 3 for this simulation (last rewards = 5384.72).
- Player #2, '#2<$\rho^{\mathrm{Learn}}$, BayesUCB, rank ~ BayesUCB>'	was ranked	3 / 3 for this simulation (last rewards = 5229.52).
plots/MP__M3_T10000_N50__3_algos is already a directory here...


- Plotting the centralized regret for all 'players' values
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized____env1-1_2239892366704700756 ...
  - For 3 players, Anandtharam et al. centralized lower-bound gave = 7.4 ...
  - For 3 players, our lower bound gave = 22.2 ...
  - For 3 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 10.8 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
 - [Anandtharam et al] centralized lowerbound = 22.2,
 - Our decentralized lowerbound = 10.8,
 - [Anandkumar et al] decentralized lowerbound = 7.4
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized____env1-1_2239892366704700756.png' created of size '189172b', at 'Wed Mar 22 09:26:37 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized____env1-1_2239892366704700756.pdf' created of size '56249b', at 'Wed Mar 22 09:26:37 2017' ...


- Plotting the centralized regret for all 'players' values, in semilogx scale
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogx____env1-1_2239892366704700756 ...
  - For 3 players, Anandtharam et al. centralized lower-bound gave = 7.4 ...
  - For 3 players, our lower bound gave = 22.2 ...
  - For 3 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 10.8 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
 - [Anandtharam et al] centralized lowerbound = 22.2,
 - Our decentralized lowerbound = 10.8,
 - [Anandkumar et al] decentralized lowerbound = 7.4
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogx____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogx____env1-1_2239892366704700756.png' created of size '179351b', at 'Wed Mar 22 09:26:39 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogx____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogx____env1-1_2239892366704700756.pdf' created of size '55889b', at 'Wed Mar 22 09:26:39 2017' ...


- Plotting the centralized regret for all 'players' values, in semilogy scale
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogy____env1-1_2239892366704700756 ...
  - For 3 players, Anandtharam et al. centralized lower-bound gave = 7.4 ...
  - For 3 players, our lower bound gave = 22.2 ...
  - For 3 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 10.8 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
 - [Anandtharam et al] centralized lowerbound = 22.2,
 - Our decentralized lowerbound = 10.8,
 - [Anandkumar et al] decentralized lowerbound = 7.4
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogy____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogy____env1-1_2239892366704700756.png' created of size '217536b', at 'Wed Mar 22 09:26:41 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogy____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_semilogy____env1-1_2239892366704700756.pdf' created of size '119636b', at 'Wed Mar 22 09:26:41 2017' ...


- Plotting the centralized regret for all 'players' values, in loglog scale
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_loglog____env1-1_2239892366704700756 ...
  - For 3 players, Anandtharam et al. centralized lower-bound gave = 7.4 ...
  - For 3 players, our lower bound gave = 22.2 ...
  - For 3 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 10.8 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 9.46 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 60.00% ...
 - [Anandtharam et al] centralized lowerbound = 22.2,
 - Our decentralized lowerbound = 10.8,
 - [Anandkumar et al] decentralized lowerbound = 7.4
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_loglog____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_loglog____env1-1_2239892366704700756.png' created of size '230621b', at 'Wed Mar 22 09:26:43 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_loglog____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_RegretCentralized_loglog____env1-1_2239892366704700756.pdf' created of size '136988b', at 'Wed Mar 22 09:26:43 2017' ...


- Plotting the centralized fairness (STD)
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all____env1-1_2239892366704700756 ...
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all____env1-1_2239892366704700756.png' created of size '216726b', at 'Wed Mar 22 09:26:44 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all____env1-1_2239892366704700756.pdf' created of size '251548b', at 'Wed Mar 22 09:26:44 2017' ...
 - Plotting the total nb of collision as a function of time for all 'players' values
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all_NbCollisions____env1-1_2239892366704700756 ...
No upper bound for the non-cumulated number of collisions...
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all_NbCollisions____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_NbCollisions____env1-1_2239892366704700756.png' created of size '348097b', at 'Wed Mar 22 09:26:45 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all_NbCollisions____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_NbCollisions____env1-1_2239892366704700756.pdf' created of size '69604b', at 'Wed Mar 22 09:26:46 2017' ...
 - Plotting the cumulated total nb of collision as a function of time for all 'players' values
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all_CumNbCollisions____env1-1_2239892366704700756 ...
No upper bound for the non-cumulated number of collisions...
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all_CumNbCollisions____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_CumNbCollisions____env1-1_2239892366704700756.png' created of size '151047b', at 'Wed Mar 22 09:26:50 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all_CumNbCollisions____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_CumNbCollisions____env1-1_2239892366704700756.pdf' created of size '43150b', at 'Wed Mar 22 09:26:50 2017' ...


- Plotting the number of switches as a function of time for all 'players' values
  and saving the plot to plots/MP__M3_T10000_N50__3_algos/all_CumNbSwitchs____env1-1_2239892366704700756 ...
Saving figure with format png, to file 'plots/MP__M3_T10000_N50__3_algos/all_CumNbSwitchs____env1-1_2239892366704700756.png'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_CumNbSwitchs____env1-1_2239892366704700756.png' created of size '157827b', at 'Wed Mar 22 09:26:51 2017' ...
Saving figure with format pdf, to file 'plots/MP__M3_T10000_N50__3_algos/all_CumNbSwitchs____env1-1_2239892366704700756.pdf'...
       Saved! 'plots/MP__M3_T10000_N50__3_algos/all_CumNbSwitchs____env1-1_2239892366704700756.pdf' created of size '46318b', at 'Wed Mar 22 09:26:51 2017' ...


==> To see the figures, do :
eog plots/MP__M3_T10000_N50__3_algos/all*2239892366704700756.png
Done for simulations main_multiplayers.py ...
