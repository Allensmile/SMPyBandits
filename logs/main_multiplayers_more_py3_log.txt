 - Setting dpi of all figures to 110 ...
 - Setting 'figsize' of all figures to (19.8, 10.8) ...
Info: numba.jit seems to be available.
Info: numba.jit seems to be available.
 - One new child, of index 0, and class #1<CentralizedMultiplePlay(UCB)> ...
 - One new child, of index 1, and class #2<CentralizedMultiplePlay(UCB)> ...
 - One new child, of index 2, and class #3<CentralizedMultiplePlay(UCB)> ...
 - One new child, of index 3, and class #4<CentralizedMultiplePlay(UCB)> ...
 - One new child, of index 4, and class #5<CentralizedMultiplePlay(UCB)> ...
 - One new child, of index 5, and class #6<CentralizedMultiplePlay(UCB)> ...
Loaded experiments configuration from 'configuration.py' :
configuration = {'averageOn': 0.001, 'delta_t_save': 1, 'verbosity': 6, 'collisionModel': <function onlyUniqUserGetsReward at 0x7f629e104a60>, 'successive_players': [[Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$))], [Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$))], [Selfish(MOSS), Selfish(MOSS), Selfish(MOSS), Selfish(MOSS), Selfish(MOSS), Selfish(MOSS)], [Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern))], [Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern))], [Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson)], [Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing))], [Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB)], [Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$))]], 'n_jobs': -1, 'environment': [{'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]}], 'finalRanksOnAverage': True, 'players': [CentralizedMultiplePlay(UCB), CentralizedMultiplePlay(UCB), CentralizedMultiplePlay(UCB), CentralizedMultiplePlay(UCB), CentralizedMultiplePlay(UCB), CentralizedMultiplePlay(UCB)], 'repetitions': 4, 'horizon': 5000}
plots/ is already a directory here...



Considering the list of players :
 [Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$)), Selfish(UCB($\alpha=1$))]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(UCB($\alpha=1$))> ...
  Using this already created player 'player' = #1<Selfish(UCB($\alpha=1$))> ...
- Adding player #2 = #2<Selfish(UCB($\alpha=1$))> ...
  Using this already created player 'player' = #2<Selfish(UCB($\alpha=1$))> ...
- Adding player #3 = #3<Selfish(UCB($\alpha=1$))> ...
  Using this already created player 'player' = #3<Selfish(UCB($\alpha=1$))> ...
- Adding player #4 = #4<Selfish(UCB($\alpha=1$))> ...
  Using this already created player 'player' = #4<Selfish(UCB($\alpha=1$))> ...
- Adding player #5 = #5<Selfish(UCB($\alpha=1$))> ...
  Using this already created player 'player' = #5<Selfish(UCB($\alpha=1$))> ...
- Adding player #6 = #6<Selfish(UCB($\alpha=1$))> ...
  Using this already created player 'player' = #6<Selfish(UCB($\alpha=1$))> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #6, '#6<Selfish(UCB($\alpha=1$))>'	was ranked	1 / 6 for this simulation (last rewards = 3995.25).
- Player #5, '#5<Selfish(UCB($\alpha=1$))>'	was ranked	2 / 6 for this simulation (last rewards = 3987.25).
- Player #2, '#2<Selfish(UCB($\alpha=1$))>'	was ranked	3 / 6 for this simulation (last rewards = 3956).
- Player #4, '#4<Selfish(UCB($\alpha=1$))>'	was ranked	4 / 6 for this simulation (last rewards = 3899.5).
- Player #3, '#3<Selfish(UCB($\alpha=1$))>'	was ranked	5 / 6 for this simulation (last rewards = 3896.5).
- Player #1, '#1<Selfish(UCB($\alpha=1$))>'	was ranked	6 / 6 for this simulation (last rewards = 3836).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.57735027  0.5527708   0.56655772 ...,  0.02816609  0.02810353
  0.02808945] ...
  - Mean fairness index is = [ 0.62578342  0.4929236   0.53737865 ...,  0.02273068  0.0226661
  0.02267887] ...
  - Default fairness index is = [ 0.62578342  0.4929236   0.53737865 ...,  0.02273068  0.0226661
  0.02267887] ...
  - Amplitude fairness index is = [ 1.          0.75        0.83333333 ...,  0.03977983  0.03964978
  0.03970239] ...
  - RajJain fairness index is = [  3.00000000e-01   1.76000000e-01   2.12244898e-01 ...,   2.46121736e-04
   2.44992561e-04   2.44781305e-04] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 0.000141667  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 0.000116667  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 0.000166667  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 0.000116667  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.000208333  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.0003  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 0.000341667  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 0.0003  ...
  - For #$8$: $B(0.5)$ ($0.1%$$\%$),	frequency of collisions is 0.000541667  ...
  - For #$9$: $B(0.55)$ ($0.1%$$\%$),	frequency of collisions is 0.000658333  ...
  - For #$10$: $B(0.6)$ ($0.1%$$\%$),	frequency of collisions is 0.000775  ...
  - For #$11$: $B(0.78)$ ($0.3%$$\%$),	frequency of collisions is 0.00275833  ...
  - For #$12$: $B(0.8)$ ($0.3%$$\%$),	frequency of collisions is 0.00273333  ...
  - For #$13$: $B(0.82)$ ($0.3%$$\%$),	frequency of collisions is 0.00323333  ...
  - For #$14$: $B(0.83)$ ($0.3%$$\%$),	frequency of collisions is 0.002675  ...
  - For #$15$: $B(0.84)$ ($0.3%$$\%$),	frequency of collisions is 0.00334167  ...
  - For #$16$: $B(0.85)$ ($0.4%$$\%$),	frequency of collisions is 0.00355  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$)), Selfish(UCB($\alpha=0.25$))]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(UCB($\alpha=0.25$))> ...
  Using this already created player 'player' = #1<Selfish(UCB($\alpha=0.25$))> ...
- Adding player #2 = #2<Selfish(UCB($\alpha=0.25$))> ...
  Using this already created player 'player' = #2<Selfish(UCB($\alpha=0.25$))> ...
- Adding player #3 = #3<Selfish(UCB($\alpha=0.25$))> ...
  Using this already created player 'player' = #3<Selfish(UCB($\alpha=0.25$))> ...
- Adding player #4 = #4<Selfish(UCB($\alpha=0.25$))> ...
  Using this already created player 'player' = #4<Selfish(UCB($\alpha=0.25$))> ...
- Adding player #5 = #5<Selfish(UCB($\alpha=0.25$))> ...
  Using this already created player 'player' = #5<Selfish(UCB($\alpha=0.25$))> ...
- Adding player #6 = #6<Selfish(UCB($\alpha=0.25$))> ...
  Using this already created player 'player' = #6<Selfish(UCB($\alpha=0.25$))> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #3, '#3<Selfish(UCB($\alpha=0.25$))>'	was ranked	1 / 6 for this simulation (last rewards = 4155).
- Player #2, '#2<Selfish(UCB($\alpha=0.25$))>'	was ranked	2 / 6 for this simulation (last rewards = 4085.75).
- Player #5, '#5<Selfish(UCB($\alpha=0.25$))>'	was ranked	3 / 6 for this simulation (last rewards = 4046.75).
- Player #1, '#1<Selfish(UCB($\alpha=0.25$))>'	was ranked	4 / 6 for this simulation (last rewards = 4008.5).
- Player #6, '#6<Selfish(UCB($\alpha=0.25$))>'	was ranked	5 / 6 for this simulation (last rewards = 3995).
- Player #4, '#4<Selfish(UCB($\alpha=0.25$))>'	was ranked	6 / 6 for this simulation (last rewards = 3831.25).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.74535599  0.32659863  0.1490712  ...,  0.04791351  0.04795024
  0.04801957] ...
  - Mean fairness index is = [ 0.67702343  0.25819954  0.11872113 ...,  0.04214099  0.04216743
  0.04222511] ...
  - Default fairness index is = [ 0.67702343  0.25819954  0.11872113 ...,  0.04214099  0.04216743
  0.04222511] ...
  - Amplitude fairness index is = [ 1.          0.4         0.2        ...,  0.07777444  0.07781586
  0.07791739] ...
  - RajJain fairness index is = [ 0.28571429  0.048       0.0070922  ...,  0.00073502  0.00073618
  0.00073836] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 0.000141667  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 7.5e-05  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 0.000116667  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.000125  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.0001  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 0.00015  ...
  - For #$8$: $B(0.5)$ ($0.0%$$\%$),	frequency of collisions is 0.000208333  ...
  - For #$9$: $B(0.55)$ ($0.0%$$\%$),	frequency of collisions is 0.000308333  ...
  - For #$10$: $B(0.6)$ ($0.0%$$\%$),	frequency of collisions is 0.000308333  ...
  - For #$11$: $B(0.78)$ ($0.1%$$\%$),	frequency of collisions is 0.000708333  ...
  - For #$12$: $B(0.8)$ ($0.1%$$\%$),	frequency of collisions is 0.000908333  ...
  - For #$13$: $B(0.82)$ ($0.1%$$\%$),	frequency of collisions is 0.000775  ...
  - For #$14$: $B(0.83)$ ($0.1%$$\%$),	frequency of collisions is 0.00110833  ...
  - For #$15$: $B(0.84)$ ($0.1%$$\%$),	frequency of collisions is 0.000858333  ...
  - For #$16$: $B(0.85)$ ($0.1%$$\%$),	frequency of collisions is 0.000958333  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(MOSS), Selfish(MOSS), Selfish(MOSS), Selfish(MOSS), Selfish(MOSS), Selfish(MOSS)]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(MOSS)> ...
  Using this already created player 'player' = #1<Selfish(MOSS)> ...
- Adding player #2 = #2<Selfish(MOSS)> ...
  Using this already created player 'player' = #2<Selfish(MOSS)> ...
- Adding player #3 = #3<Selfish(MOSS)> ...
  Using this already created player 'player' = #3<Selfish(MOSS)> ...
- Adding player #4 = #4<Selfish(MOSS)> ...
  Using this already created player 'player' = #4<Selfish(MOSS)> ...
- Adding player #5 = #5<Selfish(MOSS)> ...
  Using this already created player 'player' = #5<Selfish(MOSS)> ...
- Adding player #6 = #6<Selfish(MOSS)> ...
  Using this already created player 'player' = #6<Selfish(MOSS)> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #6, '#6<Selfish(MOSS)>'	was ranked	1 / 6 for this simulation (last rewards = 4093.25).
- Player #4, '#4<Selfish(MOSS)>'	was ranked	2 / 6 for this simulation (last rewards = 3995.75).
- Player #1, '#1<Selfish(MOSS)>'	was ranked	3 / 6 for this simulation (last rewards = 3991.25).
- Player #2, '#2<Selfish(MOSS)>'	was ranked	4 / 6 for this simulation (last rewards = 3980).
- Player #5, '#5<Selfish(MOSS)>'	was ranked	5 / 6 for this simulation (last rewards = 3912).
- Player #3, '#3<Selfish(MOSS)>'	was ranked	6 / 6 for this simulation (last rewards = 3857.5).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.62853936  0.53748385  0.48562091 ...,  0.03594666  0.03595822
  0.03595933] ...
  - Mean fairness index is = [ 0.63981615  0.50686081  0.45330221 ...,  0.03132986  0.03134946
  0.03136666] ...
  - Default fairness index is = [ 0.63981615  0.50686081  0.45330221 ...,  0.03132986  0.03134946
  0.03136666] ...
  - Amplitude fairness index is = [ 1.          0.8         0.71428571 ...,  0.05763126  0.05767822
  0.05772869] ...
  - RajJain fairness index is = [ 0.29090909  0.18309859  0.16       ...,  0.00041165  0.00041194
  0.00041197] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 0.0002  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 0.000133333  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 0.000133333  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 0.000133333  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.00025  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.000133333  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 0.000266667  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 0.000225  ...
  - For #$8$: $B(0.5)$ ($0.0%$$\%$),	frequency of collisions is 0.000425  ...
  - For #$9$: $B(0.55)$ ($0.0%$$\%$),	frequency of collisions is 0.000416667  ...
  - For #$10$: $B(0.6)$ ($0.1%$$\%$),	frequency of collisions is 0.000508333  ...
  - For #$11$: $B(0.78)$ ($0.2%$$\%$),	frequency of collisions is 0.00209167  ...
  - For #$12$: $B(0.8)$ ($0.2%$$\%$),	frequency of collisions is 0.00224167  ...
  - For #$13$: $B(0.82)$ ($0.2%$$\%$),	frequency of collisions is 0.00220833  ...
  - For #$14$: $B(0.83)$ ($0.2%$$\%$),	frequency of collisions is 0.002425  ...
  - For #$15$: $B(0.84)$ ($0.2%$$\%$),	frequency of collisions is 0.00241667  ...
  - For #$16$: $B(0.85)$ ($0.2%$$\%$),	frequency of collisions is 0.00230833  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern)), Selfish(KL-UCB(Bern))]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(KL-UCB(Bern))> ...
  Using this already created player 'player' = #1<Selfish(KL-UCB(Bern))> ...
- Adding player #2 = #2<Selfish(KL-UCB(Bern))> ...
  Using this already created player 'player' = #2<Selfish(KL-UCB(Bern))> ...
- Adding player #3 = #3<Selfish(KL-UCB(Bern))> ...
  Using this already created player 'player' = #3<Selfish(KL-UCB(Bern))> ...
- Adding player #4 = #4<Selfish(KL-UCB(Bern))> ...
  Using this already created player 'player' = #4<Selfish(KL-UCB(Bern))> ...
- Adding player #5 = #5<Selfish(KL-UCB(Bern))> ...
  Using this already created player 'player' = #5<Selfish(KL-UCB(Bern))> ...
- Adding player #6 = #6<Selfish(KL-UCB(Bern))> ...
  Using this already created player 'player' = #6<Selfish(KL-UCB(Bern))> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #5, '#5<Selfish(KL-UCB(Bern))>'	was ranked	1 / 6 for this simulation (last rewards = 4102.25).
- Player #2, '#2<Selfish(KL-UCB(Bern))>'	was ranked	2 / 6 for this simulation (last rewards = 4050.75).
- Player #6, '#6<Selfish(KL-UCB(Bern))>'	was ranked	3 / 6 for this simulation (last rewards = 4005.5).
- Player #3, '#3<Selfish(KL-UCB(Bern))>'	was ranked	4 / 6 for this simulation (last rewards = 3972.25).
- Player #4, '#4<Selfish(KL-UCB(Bern))>'	was ranked	5 / 6 for this simulation (last rewards = 3899).
- Player #1, '#1<Selfish(KL-UCB(Bern))>'	was ranked	6 / 6 for this simulation (last rewards = 3860.75).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.73702773  0.54433105  0.39308255 ...,  0.04044086  0.04047136
  0.04055281] ...
  - Mean fairness index is = [ 0.74197221  0.55065003  0.37326561 ...,  0.0332497   0.03325536
  0.03331905] ...
  - Default fairness index is = [ 0.74197221  0.55065003  0.37326561 ...,  0.0332497   0.03325536
  0.03331905] ...
  - Amplitude fairness index is = [ 1.          0.83333333  0.625      ...,  0.05878769  0.05877337
  0.05888084] ...
  - RajJain fairness index is = [ 0.48888889  0.27428571  0.10171429 ...,  0.00052054  0.00052134
  0.00052352] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 0.000116667  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.000166667  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.000291667  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 0.000358333  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 0.000233333  ...
  - For #$8$: $B(0.5)$ ($0.0%$$\%$),	frequency of collisions is 0.0004  ...
  - For #$9$: $B(0.55)$ ($0.0%$$\%$),	frequency of collisions is 0.00045  ...
  - For #$10$: $B(0.6)$ ($0.1%$$\%$),	frequency of collisions is 0.00055  ...
  - For #$11$: $B(0.78)$ ($0.2%$$\%$),	frequency of collisions is 0.00221667  ...
  - For #$12$: $B(0.8)$ ($0.2%$$\%$),	frequency of collisions is 0.001975  ...
  - For #$13$: $B(0.82)$ ($0.2%$$\%$),	frequency of collisions is 0.00235833  ...
  - For #$14$: $B(0.83)$ ($0.3%$$\%$),	frequency of collisions is 0.00309167  ...
  - For #$15$: $B(0.84)$ ($0.3%$$\%$),	frequency of collisions is 0.0026  ...
  - For #$16$: $B(0.85)$ ($0.3%$$\%$),	frequency of collisions is 0.00275833  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern))]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(KL-UCB+(Bern))> ...
  Using this already created player 'player' = #1<Selfish(KL-UCB+(Bern))> ...
- Adding player #2 = #2<Selfish(KL-UCB+(Bern))> ...
  Using this already created player 'player' = #2<Selfish(KL-UCB+(Bern))> ...
- Adding player #3 = #3<Selfish(KL-UCB+(Bern))> ...
  Using this already created player 'player' = #3<Selfish(KL-UCB+(Bern))> ...
- Adding player #4 = #4<Selfish(KL-UCB+(Bern))> ...
  Using this already created player 'player' = #4<Selfish(KL-UCB+(Bern))> ...
- Adding player #5 = #5<Selfish(KL-UCB+(Bern))> ...
  Using this already created player 'player' = #5<Selfish(KL-UCB+(Bern))> ...
- Adding player #6 = #6<Selfish(KL-UCB+(Bern))> ...
  Using this already created player 'player' = #6<Selfish(KL-UCB+(Bern))> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #5, '#5<Selfish(KL-UCB+(Bern))>'	was ranked	1 / 6 for this simulation (last rewards = 4047.75).
- Player #4, '#4<Selfish(KL-UCB+(Bern))>'	was ranked	2 / 6 for this simulation (last rewards = 4023.75).
- Player #6, '#6<Selfish(KL-UCB+(Bern))>'	was ranked	3 / 6 for this simulation (last rewards = 3999).
- Player #3, '#3<Selfish(KL-UCB+(Bern))>'	was ranked	4 / 6 for this simulation (last rewards = 3981.25).
- Player #1, '#1<Selfish(KL-UCB+(Bern))>'	was ranked	5 / 6 for this simulation (last rewards = 3970.25).
- Player #2, '#2<Selfish(KL-UCB+(Bern))>'	was ranked	6 / 6 for this simulation (last rewards = 3949.5).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.62360956  0.45812285  0.15713484 ...,  0.01625317  0.01629972
  0.01631084] ...
  - Mean fairness index is = [ 0.68479293  0.4330495   0.11068298 ...,  0.01355333  0.01358758
  0.01360989] ...
  - Default fairness index is = [ 0.68479293  0.4330495   0.11068298 ...,  0.01355333  0.01358758
  0.01360989] ...
  - Amplitude fairness index is = [ 1.          0.66666667  0.16666667 ...,  0.02432549  0.02438121
  0.0244369 ] ...
  - RajJain fairness index is = [  4.30769231e-01   1.74358974e-01   8.24742268e-03 ...,   8.13312910e-05
   8.18041307e-05   8.19237839e-05] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 0.000166667  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 0.000141667  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.0001  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.000208333  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 0.000283333  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 0.000325  ...
  - For #$8$: $B(0.5)$ ($0.1%$$\%$),	frequency of collisions is 0.0005  ...
  - For #$9$: $B(0.55)$ ($0.0%$$\%$),	frequency of collisions is 0.000475  ...
  - For #$10$: $B(0.6)$ ($0.1%$$\%$),	frequency of collisions is 0.000658333  ...
  - For #$11$: $B(0.78)$ ($0.2%$$\%$),	frequency of collisions is 0.00179167  ...
  - For #$12$: $B(0.8)$ ($0.2%$$\%$),	frequency of collisions is 0.002025  ...
  - For #$13$: $B(0.82)$ ($0.2%$$\%$),	frequency of collisions is 0.00185833  ...
  - For #$14$: $B(0.83)$ ($0.2%$$\%$),	frequency of collisions is 0.00193333  ...
  - For #$15$: $B(0.84)$ ($0.2%$$\%$),	frequency of collisions is 0.00180833  ...
  - For #$16$: $B(0.85)$ ($0.2%$$\%$),	frequency of collisions is 0.0021  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson)]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(Thompson)> ...
  Using this already created player 'player' = #1<Selfish(Thompson)> ...
- Adding player #2 = #2<Selfish(Thompson)> ...
  Using this already created player 'player' = #2<Selfish(Thompson)> ...
- Adding player #3 = #3<Selfish(Thompson)> ...
  Using this already created player 'player' = #3<Selfish(Thompson)> ...
- Adding player #4 = #4<Selfish(Thompson)> ...
  Using this already created player 'player' = #4<Selfish(Thompson)> ...
- Adding player #5 = #5<Selfish(Thompson)> ...
  Using this already created player 'player' = #5<Selfish(Thompson)> ...
- Adding player #6 = #6<Selfish(Thompson)> ...
  Using this already created player 'player' = #6<Selfish(Thompson)> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #3, '#3<Selfish(Thompson)>'	was ranked	1 / 6 for this simulation (last rewards = 4003.25).
- Player #2, '#2<Selfish(Thompson)>'	was ranked	2 / 6 for this simulation (last rewards = 3997.75).
- Player #1, '#1<Selfish(Thompson)>'	was ranked	3 / 6 for this simulation (last rewards = 3987.5).
- Player #5, '#5<Selfish(Thompson)>'	was ranked	4 / 6 for this simulation (last rewards = 3883.25).
- Player #6, '#6<Selfish(Thompson)>'	was ranked	5 / 6 for this simulation (last rewards = 3794.75).
- Player #4, '#4<Selfish(Thompson)>'	was ranked	6 / 6 for this simulation (last rewards = 3690).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.89752747  0.54974742  0.62893208 ...,  0.05872306  0.05869654  0.058636  ] ...
  - Mean fairness index is = [ 0.7812271   0.55294611  0.5554218  ...,  0.04601032  0.04597545
  0.04592884] ...
  - Default fairness index is = [ 0.7812271   0.55294611  0.5554218  ...,  0.04601032  0.04597545
  0.04592884] ...
  - Amplitude fairness index is = [ 1.          0.8         0.8        ...,  0.07821473  0.07813768
  0.07806065] ...
  - RajJain fairness index is = [ 0.44615385  0.30909091  0.23733333 ...,  0.00109315  0.00109213
  0.00108987] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.0003  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.000391667  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 0.000416667  ...
  - For #$7$: $B(0.45)$ ($0.1%$$\%$),	frequency of collisions is 0.000791667  ...
  - For #$8$: $B(0.5)$ ($0.1%$$\%$),	frequency of collisions is 0.00095  ...
  - For #$9$: $B(0.55)$ ($0.1%$$\%$),	frequency of collisions is 0.00111667  ...
  - For #$10$: $B(0.6)$ ($0.2%$$\%$),	frequency of collisions is 0.0018  ...
  - For #$11$: $B(0.78)$ ($0.3%$$\%$),	frequency of collisions is 0.00321667  ...
  - For #$12$: $B(0.8)$ ($0.4%$$\%$),	frequency of collisions is 0.003825  ...
  - For #$13$: $B(0.82)$ ($0.3%$$\%$),	frequency of collisions is 0.00315  ...
  - For #$14$: $B(0.83)$ ($0.4%$$\%$),	frequency of collisions is 0.00409167  ...
  - For #$15$: $B(0.84)$ ($0.4%$$\%$),	frequency of collisions is 0.00375  ...
  - For #$16$: $B(0.85)$ ($0.4%$$\%$),	frequency of collisions is 0.00375833  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing)), Selfish(Softmax(decreasing))]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(Softmax(decreasing))> ...
  Using this already created player 'player' = #1<Selfish(Softmax(decreasing))> ...
- Adding player #2 = #2<Selfish(Softmax(decreasing))> ...
  Using this already created player 'player' = #2<Selfish(Softmax(decreasing))> ...
- Adding player #3 = #3<Selfish(Softmax(decreasing))> ...
  Using this already created player 'player' = #3<Selfish(Softmax(decreasing))> ...
- Adding player #4 = #4<Selfish(Softmax(decreasing))> ...
  Using this already created player 'player' = #4<Selfish(Softmax(decreasing))> ...
- Adding player #5 = #5<Selfish(Softmax(decreasing))> ...
  Using this already created player 'player' = #5<Selfish(Softmax(decreasing))> ...
- Adding player #6 = #6<Selfish(Softmax(decreasing))> ...
  Using this already created player 'player' = #6<Selfish(Softmax(decreasing))> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #1, '#1<Selfish(Softmax(decreasing))>'	was ranked	1 / 6 for this simulation (last rewards = 4165.75).
- Player #4, '#4<Selfish(Softmax(decreasing))>'	was ranked	2 / 6 for this simulation (last rewards = 4104.75).
- Player #2, '#2<Selfish(Softmax(decreasing))>'	was ranked	3 / 6 for this simulation (last rewards = 4061.5).
- Player #5, '#5<Selfish(Softmax(decreasing))>'	was ranked	4 / 6 for this simulation (last rewards = 4052.25).
- Player #3, '#3<Selfish(Softmax(decreasing))>'	was ranked	5 / 6 for this simulation (last rewards = 4020.5).
- Player #6, '#6<Selfish(Softmax(decreasing))>'	was ranked	6 / 6 for this simulation (last rewards = 3583.5).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.73124703  0.73153769  0.68718427 ...,  0.09171729  0.09171947
  0.09171648] ...
  - Mean fairness index is = [ 0.7326379   0.7256069   0.62375839 ...,  0.07809435  0.07810399
  0.07811179] ...
  - Default fairness index is = [ 0.7326379   0.7256069   0.62375839 ...,  0.07809435  0.07810399
  0.07811179] ...
  - Amplitude fairness index is = [ 1.          1.          0.875      ...,  0.13983203  0.13985846
  0.13988488] ...
  - RajJain fairness index is = [ 0.46666667  0.44528302  0.30909091 ...,  0.00273373  0.00273403
  0.00273402] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 0  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 0  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 0  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 5e-05  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 1.66667e-05  ...
  - For #$8$: $B(0.5)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$9$: $B(0.55)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$10$: $B(0.6)$ ($0.0%$$\%$),	frequency of collisions is 0.00015  ...
  - For #$11$: $B(0.78)$ ($0.0%$$\%$),	frequency of collisions is 0.000266667  ...
  - For #$12$: $B(0.8)$ ($0.0%$$\%$),	frequency of collisions is 0.0002  ...
  - For #$13$: $B(0.82)$ ($0.0%$$\%$),	frequency of collisions is 0.000241667  ...
  - For #$14$: $B(0.83)$ ($0.0%$$\%$),	frequency of collisions is 0.000341667  ...
  - For #$15$: $B(0.84)$ ($0.0%$$\%$),	frequency of collisions is 0.000375  ...
  - For #$16$: $B(0.85)$ ($0.0%$$\%$),	frequency of collisions is 0.000183333  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB)]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(BayesUCB)> ...
  Using this already created player 'player' = #1<Selfish(BayesUCB)> ...
- Adding player #2 = #2<Selfish(BayesUCB)> ...
  Using this already created player 'player' = #2<Selfish(BayesUCB)> ...
- Adding player #3 = #3<Selfish(BayesUCB)> ...
  Using this already created player 'player' = #3<Selfish(BayesUCB)> ...
- Adding player #4 = #4<Selfish(BayesUCB)> ...
  Using this already created player 'player' = #4<Selfish(BayesUCB)> ...
- Adding player #5 = #5<Selfish(BayesUCB)> ...
  Using this already created player 'player' = #5<Selfish(BayesUCB)> ...
- Adding player #6 = #6<Selfish(BayesUCB)> ...
  Using this already created player 'player' = #6<Selfish(BayesUCB)> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #2, '#2<Selfish(BayesUCB)>'	was ranked	1 / 6 for this simulation (last rewards = 4130).
- Player #1, '#1<Selfish(BayesUCB)>'	was ranked	2 / 6 for this simulation (last rewards = 4099).
- Player #4, '#4<Selfish(BayesUCB)>'	was ranked	3 / 6 for this simulation (last rewards = 4007.75).
- Player #6, '#6<Selfish(BayesUCB)>'	was ranked	4 / 6 for this simulation (last rewards = 3952.25).
- Player #3, '#3<Selfish(BayesUCB)>'	was ranked	5 / 6 for this simulation (last rewards = 3940.5).
- Player #5, '#5<Selfish(BayesUCB)>'	was ranked	6 / 6 for this simulation (last rewards = 3909.5).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.74535599  0.54974742  0.52869073 ...,  0.03988898  0.03988106
  0.03989447] ...
  - Mean fairness index is = [ 0.67702343  0.50803546  0.48362775 ...,  0.03129369  0.03126757
  0.03128802] ...
  - Default fairness index is = [ 0.67702343  0.50803546  0.48362775 ...,  0.03129369  0.03126757
  0.03128802] ...
  - Amplitude fairness index is = [ 1.          0.8         0.75       ...,  0.053485    0.0534148
  0.05346235] ...
  - RajJain fairness index is = [ 0.28571429  0.17435897  0.17219251 ...,  0.0005071   0.00050686
  0.00050722] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 3.33333e-05  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 5e-05  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 8.33333e-05  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 3.33333e-05  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.00015  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.00015  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 0.000191667  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 0.000191667  ...
  - For #$8$: $B(0.5)$ ($0.0%$$\%$),	frequency of collisions is 0.0002  ...
  - For #$9$: $B(0.55)$ ($0.0%$$\%$),	frequency of collisions is 0.000366667  ...
  - For #$10$: $B(0.6)$ ($0.0%$$\%$),	frequency of collisions is 0.000466667  ...
  - For #$11$: $B(0.78)$ ($0.1%$$\%$),	frequency of collisions is 0.00138333  ...
  - For #$12$: $B(0.8)$ ($0.2%$$\%$),	frequency of collisions is 0.001525  ...
  - For #$13$: $B(0.82)$ ($0.2%$$\%$),	frequency of collisions is 0.001675  ...
  - For #$14$: $B(0.83)$ ($0.2%$$\%$),	frequency of collisions is 0.001625  ...
  - For #$15$: $B(0.84)$ ($0.2%$$\%$),	frequency of collisions is 0.00178333  ...
  - For #$16$: $B(0.85)$ ($0.2%$$\%$),	frequency of collisions is 0.00176667  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png



Considering the list of players :
 [Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$)), Selfish(AdBandits($\alpha=0.5$, $T=5000$))]
Number of players in the multi-players game: 6
Time horizon: 5000
Number of repetitions: 4
Sampling rate DELTA_T_SAVE: 1
Using collision model: onlyUniqUserGetsReward
  Detail:  Simple collision model where only the players alone on one arm sample it and receive the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Bernoulli.Bernoulli'>, 'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
Number of environments to try: 1

Evaluating environment: <MAB{'nbArms': 17, 'minArm': 0.0050000000000000001, 'arms': [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], 'maxArm': 0.84999999999999998}>
- Adding player #1 = #1<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
  Using this already created player 'player' = #1<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
- Adding player #2 = #2<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
  Using this already created player 'player' = #2<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
- Adding player #3 = #3<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
  Using this already created player 'player' = #3<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
- Adding player #4 = #4<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
  Using this already created player 'player' = #4<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
- Adding player #5 = #5<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
  Using this already created player 'player' = #5<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
- Adding player #6 = #6<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
  Using this already created player 'player' = #6<Selfish(AdBandits($\alpha=0.5$, $T=5000$))> ...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #4, '#4<Selfish(AdBandits($\alpha=0.5$, $T=5000$))>'	was ranked	1 / 6 for this simulation (last rewards = 4080.25).
- Player #6, '#6<Selfish(AdBandits($\alpha=0.5$, $T=5000$))>'	was ranked	2 / 6 for this simulation (last rewards = 4008).
- Player #3, '#3<Selfish(AdBandits($\alpha=0.5$, $T=5000$))>'	was ranked	3 / 6 for this simulation (last rewards = 4004.25).
- Player #1, '#1<Selfish(AdBandits($\alpha=0.5$, $T=5000$))>'	was ranked	4 / 6 for this simulation (last rewards = 3972.25).
- Player #5, '#5<Selfish(AdBandits($\alpha=0.5$, $T=5000$))>'	was ranked	5 / 6 for this simulation (last rewards = 3923.75).
- Player #2, '#2<Selfish(AdBandits($\alpha=0.5$, $T=5000$))>'	was ranked	6 / 6 for this simulation (last rewards = 3843.25).


- Plotting the decentralized rewards


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.47140452  0.31426968  0.18856181 ...,  0.03626923  0.03619527
  0.03623948] ...
  - Mean fairness index is = [ 0.36824595  0.22798888  0.13419897 ...,  0.0315421   0.03147367
  0.03150444] ...
  - Default fairness index is = [ 0.36824595  0.22798888  0.13419897 ...,  0.0315421   0.03147367
  0.03150444] ...
  - Amplitude fairness index is = [ 0.5         0.33333333  0.2        ...,  0.05794083  0.05781126
  0.05785832] ...
  - RajJain fairness index is = [ 0.13333333  0.03636364  0.01403509 ...,  0.00041624  0.00041447
  0.00041552] ...


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the number of switches


- Plotting the cumulative number of switches
 - Plotting the probability of picking the best arm
 - Plotting the total nb of collision as a function of time
 - Plotting the cumulated total nb of collision as a function of time
 - Plotting the frequency of collision in each arm
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 9.16667e-05  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 6.66667e-05  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 5e-05  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 0.000116667  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 0.000225  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 0.000341667  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 0.000408333  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 0.000366667  ...
  - For #$8$: $B(0.5)$ ($0.1%$$\%$),	frequency of collisions is 0.000525  ...
  - For #$9$: $B(0.55)$ ($0.1%$$\%$),	frequency of collisions is 0.000741667  ...
  - For #$10$: $B(0.6)$ ($0.1%$$\%$),	frequency of collisions is 0.00100833  ...
  - For #$11$: $B(0.78)$ ($0.2%$$\%$),	frequency of collisions is 0.00228333  ...
  - For #$12$: $B(0.8)$ ($0.2%$$\%$),	frequency of collisions is 0.00236667  ...
  - For #$13$: $B(0.82)$ ($0.2%$$\%$),	frequency of collisions is 0.00223333  ...
  - For #$14$: $B(0.83)$ ($0.3%$$\%$),	frequency of collisions is 0.00278333  ...
  - For #$15$: $B(0.84)$ ($0.3%$$\%$),	frequency of collisions is 0.002725  ...
  - For #$16$: $B(0.85)$ ($0.3%$$\%$),	frequency of collisions is 0.00283333  ...


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/main*387756437008791512.png


- Plotting the centralized regret for all 'players' values
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized regret for all 'players' values
  - For 6 player, our lower bound gave = 71.75492878990443 ...
  - For 6 player, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.27851671604706 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 62.76% ...
 - Our lowerbound = 71.8,
 - anandkumar_lowerbound = 54.3


- Plotting the centralized fairness (RajJain)
  - STD fairness index is = [ 0.57735027  0.5527708   0.56655772 ...,  0.02816609  0.02810353
  0.02808945] ...
  - Mean fairness index is = [ 0.62578342  0.4929236   0.53737865 ...,  0.02273068  0.0226661
  0.02267887] ...
  - Default fairness index is = [ 0.62578342  0.4929236   0.53737865 ...,  0.02273068  0.0226661
  0.02267887] ...
  - Amplitude fairness index is = [ 1.          0.75        0.83333333 ...,  0.03977983  0.03964978
  0.03970239] ...
  - RajJain fairness index is = [  3.00000000e-01   1.76000000e-01   2.12244898e-01 ...,   2.46121736e-04
   2.44992561e-04   2.44781305e-04] ...
  - STD fairness index is = [ 0.74535599  0.32659863  0.1490712  ...,  0.04791351  0.04795024
  0.04801957] ...
  - Mean fairness index is = [ 0.67702343  0.25819954  0.11872113 ...,  0.04214099  0.04216743
  0.04222511] ...
  - Default fairness index is = [ 0.67702343  0.25819954  0.11872113 ...,  0.04214099  0.04216743
  0.04222511] ...
  - Amplitude fairness index is = [ 1.          0.4         0.2        ...,  0.07777444  0.07781586
  0.07791739] ...
  - RajJain fairness index is = [ 0.28571429  0.048       0.0070922  ...,  0.00073502  0.00073618
  0.00073836] ...
  - STD fairness index is = [ 0.62853936  0.53748385  0.48562091 ...,  0.03594666  0.03595822
  0.03595933] ...
  - Mean fairness index is = [ 0.63981615  0.50686081  0.45330221 ...,  0.03132986  0.03134946
  0.03136666] ...
  - Default fairness index is = [ 0.63981615  0.50686081  0.45330221 ...,  0.03132986  0.03134946
  0.03136666] ...
  - Amplitude fairness index is = [ 1.          0.8         0.71428571 ...,  0.05763126  0.05767822
  0.05772869] ...
  - RajJain fairness index is = [ 0.29090909  0.18309859  0.16       ...,  0.00041165  0.00041194
  0.00041197] ...
  - STD fairness index is = [ 0.73702773  0.54433105  0.39308255 ...,  0.04044086  0.04047136
  0.04055281] ...
  - Mean fairness index is = [ 0.74197221  0.55065003  0.37326561 ...,  0.0332497   0.03325536
  0.03331905] ...
  - Default fairness index is = [ 0.74197221  0.55065003  0.37326561 ...,  0.0332497   0.03325536
  0.03331905] ...
  - Amplitude fairness index is = [ 1.          0.83333333  0.625      ...,  0.05878769  0.05877337
  0.05888084] ...
  - RajJain fairness index is = [ 0.48888889  0.27428571  0.10171429 ...,  0.00052054  0.00052134
  0.00052352] ...
  - STD fairness index is = [ 0.62360956  0.45812285  0.15713484 ...,  0.01625317  0.01629972
  0.01631084] ...
  - Mean fairness index is = [ 0.68479293  0.4330495   0.11068298 ...,  0.01355333  0.01358758
  0.01360989] ...
  - Default fairness index is = [ 0.68479293  0.4330495   0.11068298 ...,  0.01355333  0.01358758
  0.01360989] ...
  - Amplitude fairness index is = [ 1.          0.66666667  0.16666667 ...,  0.02432549  0.02438121
  0.0244369 ] ...
  - RajJain fairness index is = [  4.30769231e-01   1.74358974e-01   8.24742268e-03 ...,   8.13312910e-05
   8.18041307e-05   8.19237839e-05] ...
  - STD fairness index is = [ 0.89752747  0.54974742  0.62893208 ...,  0.05872306  0.05869654  0.058636  ] ...
  - Mean fairness index is = [ 0.7812271   0.55294611  0.5554218  ...,  0.04601032  0.04597545
  0.04592884] ...
  - Default fairness index is = [ 0.7812271   0.55294611  0.5554218  ...,  0.04601032  0.04597545
  0.04592884] ...
  - Amplitude fairness index is = [ 1.          0.8         0.8        ...,  0.07821473  0.07813768
  0.07806065] ...
  - RajJain fairness index is = [ 0.44615385  0.30909091  0.23733333 ...,  0.00109315  0.00109213
  0.00108987] ...
  - STD fairness index is = [ 0.73124703  0.73153769  0.68718427 ...,  0.09171729  0.09171947
  0.09171648] ...
  - Mean fairness index is = [ 0.7326379   0.7256069   0.62375839 ...,  0.07809435  0.07810399
  0.07811179] ...
  - Default fairness index is = [ 0.7326379   0.7256069   0.62375839 ...,  0.07809435  0.07810399
  0.07811179] ...
  - Amplitude fairness index is = [ 1.          1.          0.875      ...,  0.13983203  0.13985846
  0.13988488] ...
  - RajJain fairness index is = [ 0.46666667  0.44528302  0.30909091 ...,  0.00273373  0.00273403
  0.00273402] ...
  - STD fairness index is = [ 0.74535599  0.54974742  0.52869073 ...,  0.03988898  0.03988106
  0.03989447] ...
  - Mean fairness index is = [ 0.67702343  0.50803546  0.48362775 ...,  0.03129369  0.03126757
  0.03128802] ...
  - Default fairness index is = [ 0.67702343  0.50803546  0.48362775 ...,  0.03129369  0.03126757
  0.03128802] ...
  - Amplitude fairness index is = [ 1.          0.8         0.75       ...,  0.053485    0.0534148
  0.05346235] ...
  - RajJain fairness index is = [ 0.28571429  0.17435897  0.17219251 ...,  0.0005071   0.00050686
  0.00050722] ...
  - STD fairness index is = [ 0.47140452  0.31426968  0.18856181 ...,  0.03626923  0.03619527
  0.03623948] ...
  - Mean fairness index is = [ 0.36824595  0.22798888  0.13419897 ...,  0.0315421   0.03147367
  0.03150444] ...
  - Default fairness index is = [ 0.36824595  0.22798888  0.13419897 ...,  0.0315421   0.03147367
  0.03150444] ...
  - Amplitude fairness index is = [ 0.5         0.33333333  0.2        ...,  0.05794083  0.05781126
  0.05785832] ...
  - RajJain fairness index is = [ 0.13333333  0.03636364  0.01403509 ...,  0.00041624  0.00041447
  0.00041552] ...
 - Plotting the total nb of collision as a function of time for all 'players' values
 - Plotting the cumulated total nb of collision as a function of time for all 'players' values


- Plotting the number of switches as a function of time for all 'players' values


==> To see the figures, do :
eog plots/MP__M6_T5000_N4__6_algos/all*4436936143686730099.png
Done for simulations main_multiplayers.py ...
