 - Setting dpi of all figures to 110 ...
 - Setting 'figsize' of all figures to (19.8, 10.8) ...
Info: Using the regular tqdm() decorator ...
Info: numba.jit seems to be available.
Info: numba.jit seems to be available.
Loaded experiments configuration from 'configuration.py' :
configuration = {'n_jobs': 4, 'horizon': 10000, 'averageOn': 0.001, 'delta_t_save': 1, 'repetitions': 50, 'verbosity': 6, 'players': [rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB)], 'finalRanksOnAverage': True, 'successive_players': [[Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB)], [rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB)], [Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern)), Selfish(KL-UCB+(Bern))], [rhoRand(KL-UCB+(Bern)), rhoRand(KL-UCB+(Bern)), rhoRand(KL-UCB+(Bern)), rhoRand(KL-UCB+(Bern)), rhoRand(KL-UCB+(Bern)), rhoRand(KL-UCB+(Bern))], [Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson), Selfish(Thompson)], [rhoRand(Thompson), rhoRand(Thompson), rhoRand(Thompson), rhoRand(Thompson), rhoRand(Thompson), rhoRand(Thompson)]], 'collisionModel': <function onlyUniqUserGetsReward at 0x7f4fea7f0620>, 'environment': [{'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>}]}
plots/ is already a directory here...



Considering the list of players :
 [Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB), Selfish(BayesUCB)]
Number of players in the multi-players game: 6
Time horizon: 10000
Number of repetitions: 50
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using collision model onlyUniqUserGetsReward (function <function onlyUniqUserGetsReward at 0x7f4fea7f0620>).
More details:
 Simple collision model where only the players alone on one arm samples it and receives the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 56.88% ...
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 17, arms: [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], minArm: 0.005, maxArm: 0.85)
- Adding player #1 = #1<Selfish[BayesUCB]> ...
  Using this already created player 'player' = #1<Selfish[BayesUCB]> ...
- Adding player #2 = #2<Selfish[BayesUCB]> ...
  Using this already created player 'player' = #2<Selfish[BayesUCB]> ...
- Adding player #3 = #3<Selfish[BayesUCB]> ...
  Using this already created player 'player' = #3<Selfish[BayesUCB]> ...
- Adding player #4 = #4<Selfish[BayesUCB]> ...
  Using this already created player 'player' = #4<Selfish[BayesUCB]> ...
- Adding player #5 = #5<Selfish[BayesUCB]> ...
  Using this already created player 'player' = #5<Selfish[BayesUCB]> ...
- Adding player #6 = #6<Selfish[BayesUCB]> ...
  Using this already created player 'player' = #6<Selfish[BayesUCB]> ...

Estimated order by the policy #1<Selfish[BayesUCB]> after 10000 steps: [ 5  9  7  0  1  2  3  4  6 14 12  8 15 11 13 10 16] ...
  ==> Optimal arm identification: 89.23% (relative success)...
  ==> Manhattan   distance from optimal ordering: 61.25% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.70% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.85% (relative success)...
  ==> Gestalt     distance from optimal ordering: 52.94% (relative success)...
  ==> Mean distance from optimal ordering: 78.43% (relative success)...

Estimated order by the policy #2<Selfish[BayesUCB]> after 10000 steps: [10  9 14  8 16 15  7  6  4  5  3  2 12 13  1  0 11] ...
  ==> Optimal arm identification: 49.39% (relative success)...
  ==> Manhattan   distance from optimal ordering: 19.72% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 97.39% (relative success)...
  ==> Spearman    distance from optimal ordering: 90.81% (relative success)...
  ==> Gestalt     distance from optimal ordering: 23.53% (relative success)...
  ==> Mean distance from optimal ordering: 57.86% (relative success)...

Estimated order by the policy #3<Selfish[BayesUCB]> after 10000 steps: [ 0  1  2  3 13  9 16  4 10  7 12  6 11  5 15  8 14] ...
  ==> Optimal arm identification: 75.20% (relative success)...
  ==> Manhattan   distance from optimal ordering: 61.25% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 98.31% (relative success)...
  ==> Spearman    distance from optimal ordering: 97.96% (relative success)...
  ==> Gestalt     distance from optimal ordering: 35.29% (relative success)...
  ==> Mean distance from optimal ordering: 73.20% (relative success)...

Estimated order by the policy #4<Selfish[BayesUCB]> after 10000 steps: [ 0  1  2  3 14 12 15  5 16  9 11  8  6  4  7 10 13] ...
  ==> Optimal arm identification: 62.40% (relative success)...
  ==> Manhattan   distance from optimal ordering: 51.56% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 88.25% (relative success)...
  ==> Spearman    distance from optimal ordering: 86.47% (relative success)...
  ==> Gestalt     distance from optimal ordering: 41.18% (relative success)...
  ==> Mean distance from optimal ordering: 66.86% (relative success)...

Estimated order by the policy #5<Selfish[BayesUCB]> after 10000 steps: [ 0 13 11 16  2  1  3 15  4  6  7 14  9  8 10  5 12] ...
  ==> Optimal arm identification: 73.78% (relative success)...
  ==> Manhattan   distance from optimal ordering: 37.72% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 67.72% (relative success)...
  ==> Spearman    distance from optimal ordering: 42.67% (relative success)...
  ==> Gestalt     distance from optimal ordering: 41.18% (relative success)...
  ==> Mean distance from optimal ordering: 47.32% (relative success)...

Estimated order by the policy #6<Selfish[BayesUCB]> after 10000 steps: [ 5  6  4 14  0  1  2  3 13 11 10  8  7 16 12  9 15] ...
  ==> Optimal arm identification: 81.10% (relative success)...
  ==> Manhattan   distance from optimal ordering: 54.33% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 96.06% (relative success)...
  ==> Spearman    distance from optimal ordering: 98.28% (relative success)...
  ==> Gestalt     distance from optimal ordering: 35.29% (relative success)...
  ==> Mean distance from optimal ordering: 70.99% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Player #2, '#2<Selfish[BayesUCB]>'	was ranked	1 / 6 for this simulation (last rewards = 8147.08).
- Player #6, '#6<Selfish[BayesUCB]>'	was ranked	2 / 6 for this simulation (last rewards = 8110.94).
- Player #5, '#5<Selfish[BayesUCB]>'	was ranked	3 / 6 for this simulation (last rewards = 8099.08).
- Player #1, '#1<Selfish[BayesUCB]>'	was ranked	4 / 6 for this simulation (last rewards = 8085.28).
- Player #3, '#3<Selfish[BayesUCB]>'	was ranked	5 / 6 for this simulation (last rewards = 8078.78).
- Player #4, '#4<Selfish[BayesUCB]>'	was ranked	6 / 6 for this simulation (last rewards = 8004.96).
plots/MP__M6_T10000_N50__6_algos is already a directory here...


- Plotting the decentralized rewards
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main____env1-6_237999330670321626 ...
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main____env1-6_237999330670321626.png' created of size '191492b', at 'Mon Mar 27 14:46:35 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main____env1-6_237999330670321626.pdf' created of size '48670b', at 'Mon Mar 27 14:46:35 2017' ...


- Plotting the centralized fairness (STD)
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_FairnessSTD____env1-6_237999330670321626 ...
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_FairnessSTD____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_FairnessSTD____env1-6_237999330670321626.png' created of size '120151b', at 'Mon Mar 27 14:46:36 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_FairnessSTD____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_FairnessSTD____env1-6_237999330670321626.pdf' created of size '56202b', at 'Mon Mar 27 14:46:36 2017' ...


- Plotting the centralized regret
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized____env1-6_237999330670321626 ...
Difference between regret and sum of three terms: [  1.40000000e-03   1.70000000e-03   1.47500000e-01 ...,  -9.26590000e+00
  -9.13490000e+00  -9.06390000e+00]
  - For 6 players, Anandtharam et al. centralized lower-bound gave = 12 ...
  - For 6 players, our lower bound gave = 71.8 ...
  - For 6 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.3 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 56.88% ...
 - [Anandtharam et al] centralized lowerbound = 71.8,
 - Our decentralized lowerbound = 54.3,
 - [Anandkumar et al] decentralized lowerbound = 12
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized____env1-6_237999330670321626.png' created of size '262914b', at 'Mon Mar 27 14:46:36 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized____env1-6_237999330670321626.pdf' created of size '102352b', at 'Mon Mar 27 14:46:37 2017' ...


- Plotting the centralized regret
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogx____env1-6_237999330670321626 ...
Difference between regret and sum of three terms: [ 2.2396  2.097   1.8428 ..., -9.2659 -9.1349 -9.0639]
  - For 6 players, Anandtharam et al. centralized lower-bound gave = 12 ...
  - For 6 players, our lower bound gave = 71.8 ...
  - For 6 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.3 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 56.88% ...
 - [Anandtharam et al] centralized lowerbound = 71.8,
 - Our decentralized lowerbound = 54.3,
 - [Anandkumar et al] decentralized lowerbound = 12
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogx____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogx____env1-6_237999330670321626.png' created of size '250232b', at 'Mon Mar 27 14:46:38 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogx____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogx____env1-6_237999330670321626.pdf' created of size '102566b', at 'Mon Mar 27 14:46:38 2017' ...


- Plotting the centralized regret
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogy____env1-6_237999330670321626 ...
Difference between regret and sum of three terms: [  1.40000000e-03   1.70000000e-03   1.47500000e-01 ...,  -9.26590000e+00
  -9.13490000e+00  -9.06390000e+00]
  - For 6 players, Anandtharam et al. centralized lower-bound gave = 12 ...
  - For 6 players, our lower bound gave = 71.8 ...
  - For 6 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.3 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 56.88% ...
 - [Anandtharam et al] centralized lowerbound = 71.8,
 - Our decentralized lowerbound = 54.3,
 - [Anandkumar et al] decentralized lowerbound = 12
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogy____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogy____env1-6_237999330670321626.png' created of size '211675b', at 'Mon Mar 27 14:46:39 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogy____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_semilogy____env1-6_237999330670321626.pdf' created of size '59819b', at 'Mon Mar 27 14:46:39 2017' ...


- Plotting the centralized regret
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_loglog____env1-6_237999330670321626 ...
Difference between regret and sum of three terms: [ 2.2396  2.097   1.8428 ..., -9.2659 -9.1349 -9.0639]
  - For 6 players, Anandtharam et al. centralized lower-bound gave = 12 ...
  - For 6 players, our lower bound gave = 71.8 ...
  - For 6 players, the initial lower bound in Theorem 6 from [Anandkumar et al., 2010] gave = 54.3 ...

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 for 1-player problem ... 
 - a Optimal Arm Identification factor H_OI(mu) = 56.88% ...
 - [Anandtharam et al] centralized lowerbound = 71.8,
 - Our decentralized lowerbound = 54.3,
 - [Anandkumar et al] decentralized lowerbound = 12
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_loglog____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_loglog____env1-6_237999330670321626.png' created of size '225662b', at 'Mon Mar 27 14:46:40 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_loglog____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_RegretCentralized_loglog____env1-6_237999330670321626.pdf' created of size '74213b', at 'Mon Mar 27 14:46:40 2017' ...


- Plotting the cumulative number of switches
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_CumNbSwitchs____env1-6_237999330670321626 ...
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_CumNbSwitchs____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_CumNbSwitchs____env1-6_237999330670321626.png' created of size '208967b', at 'Mon Mar 27 14:46:41 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_CumNbSwitchs____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_CumNbSwitchs____env1-6_237999330670321626.pdf' created of size '117601b', at 'Mon Mar 27 14:46:41 2017' ...
 - Plotting the probability of picking the best arm
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_BestArmPulls____env1-6_237999330670321626 ...
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_BestArmPulls____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_BestArmPulls____env1-6_237999330670321626.png' created of size '181472b', at 'Mon Mar 27 14:46:41 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_BestArmPulls____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_BestArmPulls____env1-6_237999330670321626.pdf' created of size '51184b', at 'Mon Mar 27 14:46:41 2017' ...
 - Plotting the cumulated total nb of collision as a function of time
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_CumNbCollisions____env1-6_237999330670321626 ...
No upper bound for the non-cumulated number of collisions...
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_CumNbCollisions____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_CumNbCollisions____env1-6_237999330670321626.png' created of size '111391b', at 'Mon Mar 27 14:46:42 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_CumNbCollisions____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_CumNbCollisions____env1-6_237999330670321626.pdf' created of size '51040b', at 'Mon Mar 27 14:46:42 2017' ...
 - Plotting the frequency of collision in each arm
  and saving the plot to plots/MP__M6_T10000_N50__6_algos/main_FrequencyCollisions____env1-6_237999330670321626 ...
  - For #$0$: $B(0.005)$ ($0.0%$$\%$),	frequency of collisions is 2e-05  ...
  - For #$1$: $B(0.01)$ ($0.0%$$\%$),	frequency of collisions is 2.53333e-05  ...
  - For #$2$: $B(0.015)$ ($0.0%$$\%$),	frequency of collisions is 1.83333e-05  ...
  - For #$3$: $B(0.02)$ ($0.0%$$\%$),	frequency of collisions is 2.76667e-05  ...
  - For #$4$: $B(0.3)$ ($0.0%$$\%$),	frequency of collisions is 4.86667e-05  ...
  - For #$5$: $B(0.35)$ ($0.0%$$\%$),	frequency of collisions is 6.06667e-05  ...
  - For #$6$: $B(0.4)$ ($0.0%$$\%$),	frequency of collisions is 9.06667e-05  ...
  - For #$7$: $B(0.45)$ ($0.0%$$\%$),	frequency of collisions is 8.5e-05  ...
  - For #$8$: $B(0.5)$ ($0.0%$$\%$),	frequency of collisions is 0.000111  ...
  - For #$9$: $B(0.55)$ ($0.0%$$\%$),	frequency of collisions is 0.000147333  ...
  - For #$10$: $B(0.6)$ ($0.0%$$\%$),	frequency of collisions is 0.000186  ...
  - For #$11$: $B(0.78)$ ($0.1%$$\%$),	frequency of collisions is 0.000863  ...
  - For #$12$: $B(0.8)$ ($0.1%$$\%$),	frequency of collisions is 0.000981667  ...
  - For #$13$: $B(0.82)$ ($0.1%$$\%$),	frequency of collisions is 0.000904  ...
  - For #$14$: $B(0.83)$ ($0.1%$$\%$),	frequency of collisions is 0.000956667  ...
  - For #$15$: $B(0.84)$ ($0.1%$$\%$),	frequency of collisions is 0.000975333  ...
  - For #$16$: $B(0.85)$ ($0.1%$$\%$),	frequency of collisions is 0.00100433  ...
Saving figure with format png, to file 'plots/MP__M6_T10000_N50__6_algos/main_FrequencyCollisions____env1-6_237999330670321626.png'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_FrequencyCollisions____env1-6_237999330670321626.png' created of size '148774b', at 'Mon Mar 27 14:46:43 2017' ...
Saving figure with format pdf, to file 'plots/MP__M6_T10000_N50__6_algos/main_FrequencyCollisions____env1-6_237999330670321626.pdf'...
       Saved! 'plots/MP__M6_T10000_N50__6_algos/main_FrequencyCollisions____env1-6_237999330670321626.pdf' created of size '36049b', at 'Mon Mar 27 14:46:43 2017' ...


==> To see the figures, do :
eog plots/MP__M6_T10000_N50__6_algos/main*237999330670321626.png



Considering the list of players :
 [rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB), rhoRand(BayesUCB)]
Number of players in the multi-players game: 6
Time horizon: 10000
Number of repetitions: 50
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using collision model onlyUniqUserGetsReward (function <function onlyUniqUserGetsReward at 0x7f4fea7f0620>).
More details:
 Simple collision model where only the players alone on one arm samples it and receives the reward.

    - This is the default collision model, cf. https://arxiv.org/abs/0910.2065v3 collision model 1.
    - The numpy array 'choices' is increased according to the number of users who collided (it is NOT binary).
    
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.005, 0.01, 0.015, 0.02, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85]
 - with 'arms' = [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)]
 - with 'nbArms' = 17
 - with 'maxArm' = 0.85
 - with 'minArm' = 0.005

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 66.4 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 56.88% ...
Number of environments to try: 1

Evaluating environment: MAB(nbArms: 17, arms: [B(0.005), B(0.01), B(0.015), B(0.02), B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.78), B(0.8), B(0.82), B(0.83), B(0.84), B(0.85)], minArm: 0.005, maxArm: 0.85)
- Adding player #1 = #1<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
  Using this already created player 'player' = #1<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
- Adding player #2 = #2<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
  Using this already created player 'player' = #2<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
- Adding player #3 = #3<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
  Using this already created player 'player' = #3<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
- Adding player #4 = #4<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
  Using this already created player 'player' = #4<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
- Adding player #5 = #5<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
  Using this already created player 'player' = #5<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
- Adding player #6 = #6<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...
  Using this already created player 'player' = #6<$\rho^{\mathrm{Rand}}$[BayesUCB]> ...

Estimated order by the policy #1<$\rho^{\mathrm{Rand}}$[BayesUCB, rank:4]> after 10000 steps: [ 0  1  2  3  5  8  6  4  9 10  7 11 12 13 14 15 16] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 91.70% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 100.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 82.35% (relative success)...
  ==> Mean distance from optimal ordering: 93.51% (relative success)...

Estimated order by the policy #2<$\rho^{\mathrm{Rand}}$[BayesUCB, rank:1]> after 10000 steps: [ 0  1  2  3  4  9  8  6  5  7 10 11 12 13 15 14 16] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 90.31% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 100.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 70.59% (relative success)...
  ==> Mean distance from optimal ordering: 90.22% (relative success)...

Estimated order by the policy #3<$\rho^{\mathrm{Rand}}$[BayesUCB, rank:5]> after 10000 steps: [ 9  8 10  7  5  6  0  3  2  1  4 12 11 14 15 13 16] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 54.33% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 90.06% (relative success)...
  ==> Spearman    distance from optimal ordering: 95.90% (relative success)...
  ==> Gestalt     distance from optimal ordering: 35.29% (relative success)...
  ==> Mean distance from optimal ordering: 68.90% (relative success)...

Estimated order by the policy #4<$\rho^{\mathrm{Rand}}$[BayesUCB, rank:6]> after 10000 steps: [ 0  1  2  3  5  6  7  4 10  9  8 11 12 14 13 15 16] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 91.70% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 100.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 76.47% (relative success)...
  ==> Mean distance from optimal ordering: 92.04% (relative success)...

Estimated order by the policy #5<$\rho^{\mathrm{Rand}}$[BayesUCB, rank:2]> after 10000 steps: [ 0  1  2  3  7  4 10  5  9  6  8 12 11 13 14 16 15] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 86.16% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 100.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 58.82% (relative success)...
  ==> Mean distance from optimal ordering: 86.25% (relative success)...

Estimated order by the policy #6<$\rho^{\mathrm{Rand}}$[BayesUCB, rank:1]> after 10000 steps: [ 0  1  2  3  4  5  6 10  8  7  9 11 12 13 15 14 16] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 94.46% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 100.00% (relative success)...
  ==> Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 76.47% (relative success)...
  ==> Mean distance from optimal ordering: 92.73% (relative success)...
